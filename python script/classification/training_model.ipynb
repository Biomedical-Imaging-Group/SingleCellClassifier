{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training model\n",
    "\n",
    "This notebook allows you to create a model to classify cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\ProjetSemestre\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Anaconda3\\envs\\ProjetSemestre\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Anaconda3\\envs\\ProjetSemestre\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Anaconda3\\envs\\ProjetSemestre\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Anaconda3\\envs\\ProjetSemestre\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Anaconda3\\envs\\ProjetSemestre\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading\n",
    "\n",
    "The loading is designed for csv file generated by the Collect Information option of the ImageJ plugin. If the class of the nuclei is not missing, the entire file will have the same class.\n",
    "\n",
    "[TODO] write the path of your measurements files, create your dataset and write the possible classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Class\n",
      "1 Nucleus minor Axis\n",
      "2 Nucleus major Axis\n",
      "3 Nucleus elongation\n",
      "4 Cell minor Axis\n",
      "5 Cell major Axis\n",
      "6 Cell elongation\n",
      "7 Nucleus area\n",
      "8 Cell area\n",
      "9 Area ratio\n",
      "10 Direct neighbours mean distance\n",
      "11 Direct neighbours variance distance\n",
      "12 Lateral neighbours alignment\n",
      "13 Lateral neighbours orientation differences\n",
      "14 Lateral neighbours mean distance\n",
      "15 Cells number in chain\n",
      "16 Cells chain non reciprocal neighbours\n",
      "17 Cells chain non reciprocal neighbours ratio\n",
      "18 Cells chain tortuosity\n",
      "19 Nucleus mean value channel 1\n",
      "20 Nucleus variance value channel 1\n",
      "21 Nucleus mean value channel 2\n",
      "22 Nucleus variance value channel 2\n",
      "23 Nucleus mean value channel 3\n",
      "24 Nucleus variance value channel 3\n",
      "25 Nucleus angular second moment\n",
      "26 Nucleus contrast\n",
      "27 Nucleus correlation\n",
      "28 Nucleus sum of squares: variance\n",
      "29 Nucleus inverse difference moment\n",
      "30 Nucleus sum average\n",
      "31 Nucleus sum variance\n",
      "32 Nucleus sum entropy\n",
      "33 Nucleus entropy\n",
      "34 Nucleus difference variance\n",
      "35 Nucleus difference entropy\n",
      "36 Nucleus information measures correlation 1\n",
      "37 Nucleus information measures correlation 2\n",
      "38 Cytoplasm mean value channel 1\n",
      "39 Cytoplasm variance value channel 1\n",
      "40 Cytoplasm mean value channel 2\n",
      "41 Cytoplasm variance value channel 2\n",
      "42 Cytoplasm mean value channel 3\n",
      "43 Cytoplasm variance value channel 3\n",
      "44 Cytoplasm angular second moment\n",
      "45 Cytoplasm contrast\n",
      "46 Cytoplasm correlation\n",
      "47 Cytoplasm sum of squares: variance\n",
      "48 Cytoplasm inverse difference moment\n",
      "49 Cytoplasm sum average\n",
      "50 Cytoplasm sum variance\n",
      "51 Cytoplasm sum entropy\n",
      "52 Cytoplasm entropy\n",
      "53 Cytoplasm difference variance\n",
      "54 Cytoplasm difference entropy\n",
      "55 Cytoplasm information measures correlation 1\n",
      "56 Cytoplasm information measures correlation 2\n",
      "57 Distance to centroid up to 5 neighbours\n",
      "58 Mean distance up to 5 neighbours\n",
      "59 Variance distance up to 5 neighbours\n",
      "60 Mean distance up to 5 connected neighbours\n",
      "61 Variance distance up to 5 connected neighbours\n",
      "62 Mean orientation difference up to 5 connected neighbours\n",
      "63 Variance orientation difference up to 5 connected neighbours\n",
      "64 Mean nucleus minor axis up to 5 connected neighbours\n",
      "65 Variance nucleus minor axis up to 5 connected neighbours\n",
      "66 Mean nucleus major axis up to 5 connected neighbours\n",
      "67 Variance nucleus major axis up to 5 connected neighbours\n",
      "68 Mean nucleus elongation up to 5 connected neighbours\n",
      "69 Variance nucleus elongation up to 5 connected neighbours\n",
      "70 Mean nucleus area up to 5 connected neighbours\n",
      "71 Variance nucleus area up to 5 connected neighbours\n",
      "72 Mean cell minor axis up to 5 connected neighbours\n",
      "73 Variance cell minor axis up to 5 connected neighbours\n",
      "74 Mean cell major axis up to 5 connected neighbours\n",
      "75 Variance cell major axis up to 5 connected neighbours\n",
      "76 Mean cell elongation up to 5 connected neighbours\n",
      "77 Variance cell elongation up to 5 connected neighbours\n",
      "78 Mean cell area up to 5 connected neighbours\n",
      "79 Variance cell area up to 5 connected neighbours\n",
      "80 Mean area ratio up to 5 connected neighbours\n",
      "81 Variance area ratio up to 5 connected neighbours\n",
      "82 Ellipse minor axis up to 5 connected neighbours\n",
      "83 Ellipse major axis up to 5 connected neighbours\n",
      "84 Ellipse elongation up to 5 connected neighbours\n",
      "85 Ellipse orientation difference up to 5 connected neighbours\n",
      "86 Ellipse mean orientation difference up to 5 connected neighbours\n",
      "87 Ellipse variance orientation difference up to 5 connected neighbours\n",
      "88 Mean nucleus mean value channel 1 up to 5 connected neighbours\n",
      "89 Mean nucleus variance value channel 1 up to 5 connected neighbours\n",
      "90 Mean nucleus mean value channel 2 up to 5 connected neighbours\n",
      "91 Mean nucleus variance value channel 2 up to 5 connected neighbours\n",
      "92 Mean nucleus mean value channel 3 up to 5 connected neighbours\n",
      "93 Mean nucleus variance value channel 3 up to 5 connected neighbours\n",
      "94 Variance nucleus mean value channel 1 up to 5 connected neighbours\n",
      "95 Variance nucleus variance value channel 1 up to 5 connected neighbours\n",
      "96 Variance nucleus mean value channel 2 up to 5 connected neighbours\n",
      "97 Variance nucleus variance value channel 2 up to 5 connected neighbours\n",
      "98 Variance nucleus mean value channel 3 up to 5 connected neighbours\n",
      "99 Variance nucleus variance value channel 3 up to 5 connected neighbours\n",
      "100 Mean nucleus angular second moment up to 5 connected neighbours\n",
      "101 Mean nucleus contrast up to 5 connected neighbours\n",
      "102 Mean nucleus correlation up to 5 connected neighbours\n",
      "103 Mean nucleus sum of squares: variance up to 5 connected neighbours\n",
      "104 Mean nucleus inverse difference moment up to 5 connected neighbours\n",
      "105 Mean nucleus sum average up to 5 connected neighbours\n",
      "106 Mean nucleus sum variance up to 5 connected neighbours\n",
      "107 Mean nucleus sum entropy up to 5 connected neighbours\n",
      "108 Mean nucleus entropy up to 5 connected neighbours\n",
      "109 Mean nucleus difference variance up to 5 connected neighbours\n",
      "110 Mean nucleus difference entropy up to 5 connected neighbours\n",
      "111 Mean nucleus information measures correlation 1 up to 5 connected neighbours\n",
      "112 Mean nucleus information measures correlation 2 up to 5 connected neighbours\n",
      "113 Variance nucleus angular second moment up to 5 connected neighbours\n",
      "114 Variance nucleus contrast up to 5 connected neighbours\n",
      "115 Variance nucleus correlation up to 5 connected neighbours\n",
      "116 Variance nucleus sum of squares: variance up to 5 connected neighbours\n",
      "117 Variance nucleus inverse difference moment up to 5 connected neighbours\n",
      "118 Variance nucleus sum average up to 5 connected neighbours\n",
      "119 Variance nucleus sum variance up to 5 connected neighbours\n",
      "120 Variance nucleus sum entropy up to 5 connected neighbours\n",
      "121 Variance nucleus entropy up to 5 connected neighbours\n",
      "122 Variance nucleus difference variance up to 5 connected neighbours\n",
      "123 Variance nucleus difference entropy up to 5 connected neighbours\n",
      "124 Variance nucleus information measures correlation 1 up to 5 connected neighbours\n",
      "125 Variance nucleus information measures correlation 2 up to 5 connected neighbours\n",
      "126 Mean cytoplasm mean value channel 1 up to 5 connected neighbours\n",
      "127 Mean cytoplasm variance value channel 1 up to 5 connected neighbours\n",
      "128 Mean cytoplasm mean value channel 2 up to 5 connected neighbours\n",
      "129 Mean cytoplasm variance value channel 2 up to 5 connected neighbours\n",
      "130 Mean cytoplasm mean value channel 3 up to 5 connected neighbours\n",
      "131 Mean cytoplasm variance value channel 3 up to 5 connected neighbours\n",
      "132 Variance cytoplasm mean value channel 1 up to 5 connected neighbours\n",
      "133 Variance cytoplasm variance value channel 1 up to 5 connected neighbours\n",
      "134 Variance cytoplasm mean value channel 2 up to 5 connected neighbours\n",
      "135 Variance cytoplasm variance value channel 2 up to 5 connected neighbours\n",
      "136 Variance cytoplasm mean value channel 3 up to 5 connected neighbours\n",
      "137 Variance cytoplasm variance value channel 3 up to 5 connected neighbours\n",
      "138 Mean cytoplasm angular second moment up to 5 connected neighbours\n",
      "139 Mean cytoplasm contrast up to 5 connected neighbours\n",
      "140 Mean cytoplasm correlation up to 5 connected neighbours\n",
      "141 Mean cytoplasm sum of squares: variance up to 5 connected neighbours\n",
      "142 Mean cytoplasm inverse difference moment up to 5 connected neighbours\n",
      "143 Mean cytoplasm sum average up to 5 connected neighbours\n",
      "144 Mean cytoplasm sum variance up to 5 connected neighbours\n",
      "145 Mean cytoplasm sum entropy up to 5 connected neighbours\n",
      "146 Mean cytoplasm entropy up to 5 connected neighbours\n",
      "147 Mean cytoplasm difference variance up to 5 connected neighbours\n",
      "148 Mean cytoplasm difference entropy up to 5 connected neighbours\n",
      "149 Mean cytoplasm information measures correlation 1 up to 5 connected neighbours\n",
      "150 Mean cytoplasm information measures correlation 2 up to 5 connected neighbours\n",
      "151 Variance cytoplasm angular second moment up to 5 connected neighbours\n",
      "152 Variance cytoplasm contrast up to 5 connected neighbours\n",
      "153 Variance cytoplasm correlation up to 5 connected neighbours\n",
      "154 Variance cytoplasm sum of squares: variance up to 5 connected neighbours\n",
      "155 Variance cytoplasm inverse difference moment up to 5 connected neighbours\n",
      "156 Variance cytoplasm sum average up to 5 connected neighbours\n",
      "157 Variance cytoplasm sum variance up to 5 connected neighbours\n",
      "158 Variance cytoplasm sum entropy up to 5 connected neighbours\n",
      "159 Variance cytoplasm entropy up to 5 connected neighbours\n",
      "160 Variance cytoplasm difference variance up to 5 connected neighbours\n",
      "161 Variance cytoplasm difference entropy up to 5 connected neighbours\n",
      "162 Variance cytoplasm information measures correlation 1 up to 5 connected neighbours\n",
      "163 Variance cytoplasm information measures correlation 2 up to 5 connected neighbours\n",
      "164 Distance to centroid up to 10 neighbours\n",
      "165 Mean distance up to 10 neighbours\n",
      "166 Variance distance up to 10 neighbours\n",
      "167 Mean distance up to 10 connected neighbours\n",
      "168 Variance distance up to 10 connected neighbours\n",
      "169 Mean orientation difference up to 10 connected neighbours\n",
      "170 Variance orientation difference up to 10 connected neighbours\n",
      "171 Mean nucleus minor axis up to 10 connected neighbours\n",
      "172 Variance nucleus minor axis up to 10 connected neighbours\n",
      "173 Mean nucleus major axis up to 10 connected neighbours\n",
      "174 Variance nucleus major axis up to 10 connected neighbours\n",
      "175 Mean nucleus elongation up to 10 connected neighbours\n",
      "176 Variance nucleus elongation up to 10 connected neighbours\n",
      "177 Mean nucleus area up to 10 connected neighbours\n",
      "178 Variance nucleus area up to 10 connected neighbours\n",
      "179 Mean cell minor axis up to 10 connected neighbours\n",
      "180 Variance cell minor axis up to 10 connected neighbours\n",
      "181 Mean cell major axis up to 10 connected neighbours\n",
      "182 Variance cell major axis up to 10 connected neighbours\n",
      "183 Mean cell elongation up to 10 connected neighbours\n",
      "184 Variance cell elongation up to 10 connected neighbours\n",
      "185 Mean cell area up to 10 connected neighbours\n",
      "186 Variance cell area up to 10 connected neighbours\n",
      "187 Mean area ratio up to 10 connected neighbours\n",
      "188 Variance area ratio up to 10 connected neighbours\n",
      "189 Ellipse minor axis up to 10 connected neighbours\n",
      "190 Ellipse major axis up to 10 connected neighbours\n",
      "191 Ellipse elongation up to 10 connected neighbours\n",
      "192 Ellipse orientation difference up to 10 connected neighbours\n",
      "193 Ellipse mean orientation difference up to 10 connected neighbours\n",
      "194 Ellipse variance orientation difference up to 10 connected neighbours\n",
      "195 Mean nucleus mean value channel 1 up to 10 connected neighbours\n",
      "196 Mean nucleus variance value channel 1 up to 10 connected neighbours\n",
      "197 Mean nucleus mean value channel 2 up to 10 connected neighbours\n",
      "198 Mean nucleus variance value channel 2 up to 10 connected neighbours\n",
      "199 Mean nucleus mean value channel 3 up to 10 connected neighbours\n",
      "200 Mean nucleus variance value channel 3 up to 10 connected neighbours\n",
      "201 Variance nucleus mean value channel 1 up to 10 connected neighbours\n",
      "202 Variance nucleus variance value channel 1 up to 10 connected neighbours\n",
      "203 Variance nucleus mean value channel 2 up to 10 connected neighbours\n",
      "204 Variance nucleus variance value channel 2 up to 10 connected neighbours\n",
      "205 Variance nucleus mean value channel 3 up to 10 connected neighbours\n",
      "206 Variance nucleus variance value channel 3 up to 10 connected neighbours\n",
      "207 Mean nucleus angular second moment up to 10 connected neighbours\n",
      "208 Mean nucleus contrast up to 10 connected neighbours\n",
      "209 Mean nucleus correlation up to 10 connected neighbours\n",
      "210 Mean nucleus sum of squares: variance up to 10 connected neighbours\n",
      "211 Mean nucleus inverse difference moment up to 10 connected neighbours\n",
      "212 Mean nucleus sum average up to 10 connected neighbours\n",
      "213 Mean nucleus sum variance up to 10 connected neighbours\n",
      "214 Mean nucleus sum entropy up to 10 connected neighbours\n",
      "215 Mean nucleus entropy up to 10 connected neighbours\n",
      "216 Mean nucleus difference variance up to 10 connected neighbours\n",
      "217 Mean nucleus difference entropy up to 10 connected neighbours\n",
      "218 Mean nucleus information measures correlation 1 up to 10 connected neighbours\n",
      "219 Mean nucleus information measures correlation 2 up to 10 connected neighbours\n",
      "220 Variance nucleus angular second moment up to 10 connected neighbours\n",
      "221 Variance nucleus contrast up to 10 connected neighbours\n",
      "222 Variance nucleus correlation up to 10 connected neighbours\n",
      "223 Variance nucleus sum of squares: variance up to 10 connected neighbours\n",
      "224 Variance nucleus inverse difference moment up to 10 connected neighbours\n",
      "225 Variance nucleus sum average up to 10 connected neighbours\n",
      "226 Variance nucleus sum variance up to 10 connected neighbours\n",
      "227 Variance nucleus sum entropy up to 10 connected neighbours\n",
      "228 Variance nucleus entropy up to 10 connected neighbours\n",
      "229 Variance nucleus difference variance up to 10 connected neighbours\n",
      "230 Variance nucleus difference entropy up to 10 connected neighbours\n",
      "231 Variance nucleus information measures correlation 1 up to 10 connected neighbours\n",
      "232 Variance nucleus information measures correlation 2 up to 10 connected neighbours\n",
      "233 Mean cytoplasm mean value channel 1 up to 10 connected neighbours\n",
      "234 Mean cytoplasm variance value channel 1 up to 10 connected neighbours\n",
      "235 Mean cytoplasm mean value channel 2 up to 10 connected neighbours\n",
      "236 Mean cytoplasm variance value channel 2 up to 10 connected neighbours\n",
      "237 Mean cytoplasm mean value channel 3 up to 10 connected neighbours\n",
      "238 Mean cytoplasm variance value channel 3 up to 10 connected neighbours\n",
      "239 Variance cytoplasm mean value channel 1 up to 10 connected neighbours\n",
      "240 Variance cytoplasm variance value channel 1 up to 10 connected neighbours\n",
      "241 Variance cytoplasm mean value channel 2 up to 10 connected neighbours\n",
      "242 Variance cytoplasm variance value channel 2 up to 10 connected neighbours\n",
      "243 Variance cytoplasm mean value channel 3 up to 10 connected neighbours\n",
      "244 Variance cytoplasm variance value channel 3 up to 10 connected neighbours\n",
      "245 Mean cytoplasm angular second moment up to 10 connected neighbours\n",
      "246 Mean cytoplasm contrast up to 10 connected neighbours\n",
      "247 Mean cytoplasm correlation up to 10 connected neighbours\n",
      "248 Mean cytoplasm sum of squares: variance up to 10 connected neighbours\n",
      "249 Mean cytoplasm inverse difference moment up to 10 connected neighbours\n",
      "250 Mean cytoplasm sum average up to 10 connected neighbours\n",
      "251 Mean cytoplasm sum variance up to 10 connected neighbours\n",
      "252 Mean cytoplasm sum entropy up to 10 connected neighbours\n",
      "253 Mean cytoplasm entropy up to 10 connected neighbours\n",
      "254 Mean cytoplasm difference variance up to 10 connected neighbours\n",
      "255 Mean cytoplasm difference entropy up to 10 connected neighbours\n",
      "256 Mean cytoplasm information measures correlation 1 up to 10 connected neighbours\n",
      "257 Mean cytoplasm information measures correlation 2 up to 10 connected neighbours\n",
      "258 Variance cytoplasm angular second moment up to 10 connected neighbours\n",
      "259 Variance cytoplasm contrast up to 10 connected neighbours\n",
      "260 Variance cytoplasm correlation up to 10 connected neighbours\n",
      "261 Variance cytoplasm sum of squares: variance up to 10 connected neighbours\n",
      "262 Variance cytoplasm inverse difference moment up to 10 connected neighbours\n",
      "263 Variance cytoplasm sum average up to 10 connected neighbours\n",
      "264 Variance cytoplasm sum variance up to 10 connected neighbours\n",
      "265 Variance cytoplasm sum entropy up to 10 connected neighbours\n",
      "266 Variance cytoplasm entropy up to 10 connected neighbours\n",
      "267 Variance cytoplasm difference variance up to 10 connected neighbours\n",
      "268 Variance cytoplasm difference entropy up to 10 connected neighbours\n",
      "269 Variance cytoplasm information measures correlation 1 up to 10 connected neighbours\n",
      "270 Variance cytoplasm information measures correlation 2 up to 10 connected neighbours\n",
      "271 Distance to centroid up to 20 neighbours\n",
      "272 Mean distance up to 20 neighbours\n",
      "273 Variance distance up to 20 neighbours\n",
      "274 Mean distance up to 20 connected neighbours\n",
      "275 Variance distance up to 20 connected neighbours\n",
      "276 Mean orientation difference up to 20 connected neighbours\n",
      "277 Variance orientation difference up to 20 connected neighbours\n",
      "278 Mean nucleus minor axis up to 20 connected neighbours\n",
      "279 Variance nucleus minor axis up to 20 connected neighbours\n",
      "280 Mean nucleus major axis up to 20 connected neighbours\n",
      "281 Variance nucleus major axis up to 20 connected neighbours\n",
      "282 Mean nucleus elongation up to 20 connected neighbours\n",
      "283 Variance nucleus elongation up to 20 connected neighbours\n",
      "284 Mean nucleus area up to 20 connected neighbours\n",
      "285 Variance nucleus area up to 20 connected neighbours\n",
      "286 Mean cell minor axis up to 20 connected neighbours\n",
      "287 Variance cell minor axis up to 20 connected neighbours\n",
      "288 Mean cell major axis up to 20 connected neighbours\n",
      "289 Variance cell major axis up to 20 connected neighbours\n",
      "290 Mean cell elongation up to 20 connected neighbours\n",
      "291 Variance cell elongation up to 20 connected neighbours\n",
      "292 Mean cell area up to 20 connected neighbours\n",
      "293 Variance cell area up to 20 connected neighbours\n",
      "294 Mean area ratio up to 20 connected neighbours\n",
      "295 Variance area ratio up to 20 connected neighbours\n",
      "296 Ellipse minor axis up to 20 connected neighbours\n",
      "297 Ellipse major axis up to 20 connected neighbours\n",
      "298 Ellipse elongation up to 20 connected neighbours\n",
      "299 Ellipse orientation difference up to 20 connected neighbours\n",
      "300 Ellipse mean orientation difference up to 20 connected neighbours\n",
      "301 Ellipse variance orientation difference up to 20 connected neighbours\n",
      "302 Mean nucleus mean value channel 1 up to 20 connected neighbours\n",
      "303 Mean nucleus variance value channel 1 up to 20 connected neighbours\n",
      "304 Mean nucleus mean value channel 2 up to 20 connected neighbours\n",
      "305 Mean nucleus variance value channel 2 up to 20 connected neighbours\n",
      "306 Mean nucleus mean value channel 3 up to 20 connected neighbours\n",
      "307 Mean nucleus variance value channel 3 up to 20 connected neighbours\n",
      "308 Variance nucleus mean value channel 1 up to 20 connected neighbours\n",
      "309 Variance nucleus variance value channel 1 up to 20 connected neighbours\n",
      "310 Variance nucleus mean value channel 2 up to 20 connected neighbours\n",
      "311 Variance nucleus variance value channel 2 up to 20 connected neighbours\n",
      "312 Variance nucleus mean value channel 3 up to 20 connected neighbours\n",
      "313 Variance nucleus variance value channel 3 up to 20 connected neighbours\n",
      "314 Mean nucleus angular second moment up to 20 connected neighbours\n",
      "315 Mean nucleus contrast up to 20 connected neighbours\n",
      "316 Mean nucleus correlation up to 20 connected neighbours\n",
      "317 Mean nucleus sum of squares: variance up to 20 connected neighbours\n",
      "318 Mean nucleus inverse difference moment up to 20 connected neighbours\n",
      "319 Mean nucleus sum average up to 20 connected neighbours\n",
      "320 Mean nucleus sum variance up to 20 connected neighbours\n",
      "321 Mean nucleus sum entropy up to 20 connected neighbours\n",
      "322 Mean nucleus entropy up to 20 connected neighbours\n",
      "323 Mean nucleus difference variance up to 20 connected neighbours\n",
      "324 Mean nucleus difference entropy up to 20 connected neighbours\n",
      "325 Mean nucleus information measures correlation 1 up to 20 connected neighbours\n",
      "326 Mean nucleus information measures correlation 2 up to 20 connected neighbours\n",
      "327 Variance nucleus angular second moment up to 20 connected neighbours\n",
      "328 Variance nucleus contrast up to 20 connected neighbours\n",
      "329 Variance nucleus correlation up to 20 connected neighbours\n",
      "330 Variance nucleus sum of squares: variance up to 20 connected neighbours\n",
      "331 Variance nucleus inverse difference moment up to 20 connected neighbours\n",
      "332 Variance nucleus sum average up to 20 connected neighbours\n",
      "333 Variance nucleus sum variance up to 20 connected neighbours\n",
      "334 Variance nucleus sum entropy up to 20 connected neighbours\n",
      "335 Variance nucleus entropy up to 20 connected neighbours\n",
      "336 Variance nucleus difference variance up to 20 connected neighbours\n",
      "337 Variance nucleus difference entropy up to 20 connected neighbours\n",
      "338 Variance nucleus information measures correlation 1 up to 20 connected neighbours\n",
      "339 Variance nucleus information measures correlation 2 up to 20 connected neighbours\n",
      "340 Mean cytoplasm mean value channel 1 up to 20 connected neighbours\n",
      "341 Mean cytoplasm variance value channel 1 up to 20 connected neighbours\n",
      "342 Mean cytoplasm mean value channel 2 up to 20 connected neighbours\n",
      "343 Mean cytoplasm variance value channel 2 up to 20 connected neighbours\n",
      "344 Mean cytoplasm mean value channel 3 up to 20 connected neighbours\n",
      "345 Mean cytoplasm variance value channel 3 up to 20 connected neighbours\n",
      "346 Variance cytoplasm mean value channel 1 up to 20 connected neighbours\n",
      "347 Variance cytoplasm variance value channel 1 up to 20 connected neighbours\n",
      "348 Variance cytoplasm mean value channel 2 up to 20 connected neighbours\n",
      "349 Variance cytoplasm variance value channel 2 up to 20 connected neighbours\n",
      "350 Variance cytoplasm mean value channel 3 up to 20 connected neighbours\n",
      "351 Variance cytoplasm variance value channel 3 up to 20 connected neighbours\n",
      "352 Mean cytoplasm angular second moment up to 20 connected neighbours\n",
      "353 Mean cytoplasm contrast up to 20 connected neighbours\n",
      "354 Mean cytoplasm correlation up to 20 connected neighbours\n",
      "355 Mean cytoplasm sum of squares: variance up to 20 connected neighbours\n",
      "356 Mean cytoplasm inverse difference moment up to 20 connected neighbours\n",
      "357 Mean cytoplasm sum average up to 20 connected neighbours\n",
      "358 Mean cytoplasm sum variance up to 20 connected neighbours\n",
      "359 Mean cytoplasm sum entropy up to 20 connected neighbours\n",
      "360 Mean cytoplasm entropy up to 20 connected neighbours\n",
      "361 Mean cytoplasm difference variance up to 20 connected neighbours\n",
      "362 Mean cytoplasm difference entropy up to 20 connected neighbours\n",
      "363 Mean cytoplasm information measures correlation 1 up to 20 connected neighbours\n",
      "364 Mean cytoplasm information measures correlation 2 up to 20 connected neighbours\n",
      "365 Variance cytoplasm angular second moment up to 20 connected neighbours\n",
      "366 Variance cytoplasm contrast up to 20 connected neighbours\n",
      "367 Variance cytoplasm correlation up to 20 connected neighbours\n",
      "368 Variance cytoplasm sum of squares: variance up to 20 connected neighbours\n",
      "369 Variance cytoplasm inverse difference moment up to 20 connected neighbours\n",
      "370 Variance cytoplasm sum average up to 20 connected neighbours\n",
      "371 Variance cytoplasm sum variance up to 20 connected neighbours\n",
      "372 Variance cytoplasm sum entropy up to 20 connected neighbours\n",
      "373 Variance cytoplasm entropy up to 20 connected neighbours\n",
      "374 Variance cytoplasm difference variance up to 20 connected neighbours\n",
      "375 Variance cytoplasm difference entropy up to 20 connected neighbours\n",
      "376 Variance cytoplasm information measures correlation 1 up to 20 connected neighbours\n",
      "377 Variance cytoplasm information measures correlation 2 up to 20 connected neighbours\n",
      "378 Distance to centroid up to 40 neighbours\n",
      "379 Mean distance up to 40 neighbours\n",
      "380 Variance distance up to 40 neighbours\n",
      "381 Mean distance up to 40 connected neighbours\n",
      "382 Variance distance up to 40 connected neighbours\n",
      "383 Mean orientation difference up to 40 connected neighbours\n",
      "384 Variance orientation difference up to 40 connected neighbours\n",
      "385 Mean nucleus minor axis up to 40 connected neighbours\n",
      "386 Variance nucleus minor axis up to 40 connected neighbours\n",
      "387 Mean nucleus major axis up to 40 connected neighbours\n",
      "388 Variance nucleus major axis up to 40 connected neighbours\n",
      "389 Mean nucleus elongation up to 40 connected neighbours\n",
      "390 Variance nucleus elongation up to 40 connected neighbours\n",
      "391 Mean nucleus area up to 40 connected neighbours\n",
      "392 Variance nucleus area up to 40 connected neighbours\n",
      "393 Mean cell minor axis up to 40 connected neighbours\n",
      "394 Variance cell minor axis up to 40 connected neighbours\n",
      "395 Mean cell major axis up to 40 connected neighbours\n",
      "396 Variance cell major axis up to 40 connected neighbours\n",
      "397 Mean cell elongation up to 40 connected neighbours\n",
      "398 Variance cell elongation up to 40 connected neighbours\n",
      "399 Mean cell area up to 40 connected neighbours\n",
      "400 Variance cell area up to 40 connected neighbours\n",
      "401 Mean area ratio up to 40 connected neighbours\n",
      "402 Variance area ratio up to 40 connected neighbours\n",
      "403 Ellipse minor axis up to 40 connected neighbours\n",
      "404 Ellipse major axis up to 40 connected neighbours\n",
      "405 Ellipse elongation up to 40 connected neighbours\n",
      "406 Ellipse orientation difference up to 40 connected neighbours\n",
      "407 Ellipse mean orientation difference up to 40 connected neighbours\n",
      "408 Ellipse variance orientation difference up to 40 connected neighbours\n",
      "409 Mean nucleus mean value channel 1 up to 40 connected neighbours\n",
      "410 Mean nucleus variance value channel 1 up to 40 connected neighbours\n",
      "411 Mean nucleus mean value channel 2 up to 40 connected neighbours\n",
      "412 Mean nucleus variance value channel 2 up to 40 connected neighbours\n",
      "413 Mean nucleus mean value channel 3 up to 40 connected neighbours\n",
      "414 Mean nucleus variance value channel 3 up to 40 connected neighbours\n",
      "415 Variance nucleus mean value channel 1 up to 40 connected neighbours\n",
      "416 Variance nucleus variance value channel 1 up to 40 connected neighbours\n",
      "417 Variance nucleus mean value channel 2 up to 40 connected neighbours\n",
      "418 Variance nucleus variance value channel 2 up to 40 connected neighbours\n",
      "419 Variance nucleus mean value channel 3 up to 40 connected neighbours\n",
      "420 Variance nucleus variance value channel 3 up to 40 connected neighbours\n",
      "421 Mean nucleus angular second moment up to 40 connected neighbours\n",
      "422 Mean nucleus contrast up to 40 connected neighbours\n",
      "423 Mean nucleus correlation up to 40 connected neighbours\n",
      "424 Mean nucleus sum of squares: variance up to 40 connected neighbours\n",
      "425 Mean nucleus inverse difference moment up to 40 connected neighbours\n",
      "426 Mean nucleus sum average up to 40 connected neighbours\n",
      "427 Mean nucleus sum variance up to 40 connected neighbours\n",
      "428 Mean nucleus sum entropy up to 40 connected neighbours\n",
      "429 Mean nucleus entropy up to 40 connected neighbours\n",
      "430 Mean nucleus difference variance up to 40 connected neighbours\n",
      "431 Mean nucleus difference entropy up to 40 connected neighbours\n",
      "432 Mean nucleus information measures correlation 1 up to 40 connected neighbours\n",
      "433 Mean nucleus information measures correlation 2 up to 40 connected neighbours\n",
      "434 Variance nucleus angular second moment up to 40 connected neighbours\n",
      "435 Variance nucleus contrast up to 40 connected neighbours\n",
      "436 Variance nucleus correlation up to 40 connected neighbours\n",
      "437 Variance nucleus sum of squares: variance up to 40 connected neighbours\n",
      "438 Variance nucleus inverse difference moment up to 40 connected neighbours\n",
      "439 Variance nucleus sum average up to 40 connected neighbours\n",
      "440 Variance nucleus sum variance up to 40 connected neighbours\n",
      "441 Variance nucleus sum entropy up to 40 connected neighbours\n",
      "442 Variance nucleus entropy up to 40 connected neighbours\n",
      "443 Variance nucleus difference variance up to 40 connected neighbours\n",
      "444 Variance nucleus difference entropy up to 40 connected neighbours\n",
      "445 Variance nucleus information measures correlation 1 up to 40 connected neighbours\n",
      "446 Variance nucleus information measures correlation 2 up to 40 connected neighbours\n",
      "447 Mean cytoplasm mean value channel 1 up to 40 connected neighbours\n",
      "448 Mean cytoplasm variance value channel 1 up to 40 connected neighbours\n",
      "449 Mean cytoplasm mean value channel 2 up to 40 connected neighbours\n",
      "450 Mean cytoplasm variance value channel 2 up to 40 connected neighbours\n",
      "451 Mean cytoplasm mean value channel 3 up to 40 connected neighbours\n",
      "452 Mean cytoplasm variance value channel 3 up to 40 connected neighbours\n",
      "453 Variance cytoplasm mean value channel 1 up to 40 connected neighbours\n",
      "454 Variance cytoplasm variance value channel 1 up to 40 connected neighbours\n",
      "455 Variance cytoplasm mean value channel 2 up to 40 connected neighbours\n",
      "456 Variance cytoplasm variance value channel 2 up to 40 connected neighbours\n",
      "457 Variance cytoplasm mean value channel 3 up to 40 connected neighbours\n",
      "458 Variance cytoplasm variance value channel 3 up to 40 connected neighbours\n",
      "459 Mean cytoplasm angular second moment up to 40 connected neighbours\n",
      "460 Mean cytoplasm contrast up to 40 connected neighbours\n",
      "461 Mean cytoplasm correlation up to 40 connected neighbours\n",
      "462 Mean cytoplasm sum of squares: variance up to 40 connected neighbours\n",
      "463 Mean cytoplasm inverse difference moment up to 40 connected neighbours\n",
      "464 Mean cytoplasm sum average up to 40 connected neighbours\n",
      "465 Mean cytoplasm sum variance up to 40 connected neighbours\n",
      "466 Mean cytoplasm sum entropy up to 40 connected neighbours\n",
      "467 Mean cytoplasm entropy up to 40 connected neighbours\n",
      "468 Mean cytoplasm difference variance up to 40 connected neighbours\n",
      "469 Mean cytoplasm difference entropy up to 40 connected neighbours\n",
      "470 Mean cytoplasm information measures correlation 1 up to 40 connected neighbours\n",
      "471 Mean cytoplasm information measures correlation 2 up to 40 connected neighbours\n",
      "472 Variance cytoplasm angular second moment up to 40 connected neighbours\n",
      "473 Variance cytoplasm contrast up to 40 connected neighbours\n",
      "474 Variance cytoplasm correlation up to 40 connected neighbours\n",
      "475 Variance cytoplasm sum of squares: variance up to 40 connected neighbours\n",
      "476 Variance cytoplasm inverse difference moment up to 40 connected neighbours\n",
      "477 Variance cytoplasm sum average up to 40 connected neighbours\n",
      "478 Variance cytoplasm sum variance up to 40 connected neighbours\n",
      "479 Variance cytoplasm sum entropy up to 40 connected neighbours\n",
      "480 Variance cytoplasm entropy up to 40 connected neighbours\n",
      "481 Variance cytoplasm difference variance up to 40 connected neighbours\n",
      "482 Variance cytoplasm difference entropy up to 40 connected neighbours\n",
      "483 Variance cytoplasm information measures correlation 1 up to 40 connected neighbours\n",
      "484 Variance cytoplasm information measures correlation 2 up to 40 connected neighbours\n"
     ]
    }
   ],
   "source": [
    "mouse_path = \"../../data/H&E/measurements/mouse features.csv\"\n",
    "human_path = \"../../data/H&E/measurements/human features.csv\"\n",
    "human_tumor_path = \"../../data/H&E/measurements/human tumor features.csv\"\n",
    "\n",
    "mouse = get_data(mouse_path, \"Mouse\")\n",
    "human = get_data(human_path, \"Human\")\n",
    "human_tumor = get_data(human_tumor_path, \"Human\")\n",
    "\n",
    "dataset = pd.concat([mouse, human, human_tumor], ignore_index=True)\n",
    "\n",
    "classes = [\"Mouse\", \"Human\"]\n",
    "\n",
    "headers = dataset.columns.values\n",
    "\n",
    "for i, header in enumerate(headers):\n",
    "    print(str(i) + \" \" + header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Human    47529\n",
       "Mouse    41511\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[CLASS_COLUMN].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing\n",
    "Shuffle, normalize and split the data between inputs and targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take the same number of values for each class, to take everything set -1\n",
    "nb_values_per_class = dataset[CLASS_COLUMN].value_counts().min()\n",
    "\n",
    "inputs, targets, mean_values, std_values = process_training_data(dataset, classes, nb_values_per_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSBDeep need 3D images with more than 1 element in each dimension, we create an image of size (2, 2, feature_size / 4). If the feature size is not a multiple of 4, it will be padded with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = inputs.shape[1]\n",
    "input_size = int(np.ceil(num_features/4) * 4)\n",
    "\n",
    "inputs = resize_inputs(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model creation\n",
    "\n",
    "Any model accepted by tensorflow can be used as long as it has the expected input and ouput."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\ProjetSemestre\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\ProjetSemestre\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape (Reshape)            (None, 484)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               62080     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "re_lu_2 (ReLU)               (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "re_lu_3 (ReLU)               (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 34        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 73,938\n",
      "Trainable params: 73,458\n",
      "Non-trainable params: 480\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.Adam()\n",
    "loss_function = 'categorical_crossentropy'\n",
    "              \n",
    "demo_model = get_model(input_size, len(classes))\n",
    "demo_model.compile(optimizer=optimizer, loss=loss_function, metrics=['accuracy'])\n",
    "demo_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Train on 49812 samples, validate on 12454 samples\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\ProjetSemestre\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "49812/49812 [==============================] - 11s 214us/sample - loss: 0.5391 - acc: 0.7499 - val_loss: 0.2975 - val_acc: 0.8873\n",
      "Epoch 2/100\n",
      "49812/49812 [==============================] - 6s 125us/sample - loss: 0.3365 - acc: 0.8768 - val_loss: 0.2168 - val_acc: 0.9175\n",
      "Epoch 3/100\n",
      "49812/49812 [==============================] - 6s 118us/sample - loss: 0.2689 - acc: 0.9074 - val_loss: 0.1695 - val_acc: 0.9371\n",
      "Epoch 4/100\n",
      "49812/49812 [==============================] - 6s 116us/sample - loss: 0.2434 - acc: 0.9176 - val_loss: 0.1640 - val_acc: 0.9350\n",
      "Epoch 5/100\n",
      "49812/49812 [==============================] - 5s 105us/sample - loss: 0.2244 - acc: 0.9232 - val_loss: 0.1453 - val_acc: 0.9456\n",
      "Epoch 6/100\n",
      "49812/49812 [==============================] - 5s 106us/sample - loss: 0.2105 - acc: 0.9283 - val_loss: 0.1373 - val_acc: 0.9464\n",
      "Epoch 7/100\n",
      "49812/49812 [==============================] - 5s 95us/sample - loss: 0.1988 - acc: 0.9309 - val_loss: 0.1438 - val_acc: 0.9399\n",
      "Epoch 8/100\n",
      "49812/49812 [==============================] - 5s 91us/sample - loss: 0.1921 - acc: 0.9327 - val_loss: 0.1285 - val_acc: 0.9491\n",
      "Epoch 9/100\n",
      "49812/49812 [==============================] - 5s 91us/sample - loss: 0.1887 - acc: 0.9345 - val_loss: 0.1329 - val_acc: 0.9458\n",
      "Epoch 10/100\n",
      "49812/49812 [==============================] - 4s 87us/sample - loss: 0.1859 - acc: 0.9352 - val_loss: 0.1263 - val_acc: 0.9479\n",
      "Epoch 11/100\n",
      "49812/49812 [==============================] - 4s 74us/sample - loss: 0.1816 - acc: 0.9366 - val_loss: 0.1232 - val_acc: 0.9492\n",
      "Epoch 12/100\n",
      "49812/49812 [==============================] - 3s 70us/sample - loss: 0.1733 - acc: 0.9379 - val_loss: 0.1223 - val_acc: 0.9509\n",
      "Epoch 13/100\n",
      "49812/49812 [==============================] - 3s 70us/sample - loss: 0.1715 - acc: 0.9385 - val_loss: 0.1218 - val_acc: 0.9481\n",
      "Epoch 14/100\n",
      "49812/49812 [==============================] - 3s 70us/sample - loss: 0.1682 - acc: 0.9385 - val_loss: 0.1232 - val_acc: 0.9497\n",
      "Epoch 15/100\n",
      "49812/49812 [==============================] - 3s 70us/sample - loss: 0.1655 - acc: 0.9410 - val_loss: 0.1185 - val_acc: 0.9518\n",
      "Epoch 16/100\n",
      "49812/49812 [==============================] - 3s 70us/sample - loss: 0.1645 - acc: 0.9414 - val_loss: 0.1169 - val_acc: 0.9511\n",
      "Epoch 17/100\n",
      "49812/49812 [==============================] - 4s 71us/sample - loss: 0.1623 - acc: 0.9409 - val_loss: 0.1163 - val_acc: 0.9529\n",
      "Epoch 18/100\n",
      "49812/49812 [==============================] - 3s 70us/sample - loss: 0.1616 - acc: 0.9417 - val_loss: 0.1162 - val_acc: 0.9515\n",
      "Epoch 19/100\n",
      "49812/49812 [==============================] - 3s 70us/sample - loss: 0.1599 - acc: 0.9431 - val_loss: 0.1120 - val_acc: 0.9537\n",
      "Epoch 20/100\n",
      "49812/49812 [==============================] - 4s 70us/sample - loss: 0.1580 - acc: 0.9442 - val_loss: 0.1126 - val_acc: 0.9536\n",
      "Epoch 21/100\n",
      "49812/49812 [==============================] - 3s 70us/sample - loss: 0.1565 - acc: 0.9449 - val_loss: 0.1157 - val_acc: 0.9540\n",
      "Epoch 22/100\n",
      "49812/49812 [==============================] - 3s 70us/sample - loss: 0.1513 - acc: 0.9456 - val_loss: 0.1128 - val_acc: 0.9527\n",
      "Epoch 23/100\n",
      "49812/49812 [==============================] - 3s 70us/sample - loss: 0.1508 - acc: 0.9449 - val_loss: 0.1127 - val_acc: 0.9541\n",
      "Epoch 24/100\n",
      "49812/49812 [==============================] - 4s 71us/sample - loss: 0.1505 - acc: 0.9462 - val_loss: 0.1127 - val_acc: 0.9546\n",
      "Epoch 25/100\n",
      "49812/49812 [==============================] - 3s 70us/sample - loss: 0.1490 - acc: 0.9472 - val_loss: 0.1148 - val_acc: 0.9525\n",
      "Epoch 26/100\n",
      "49812/49812 [==============================] - 4s 70us/sample - loss: 0.1464 - acc: 0.9473 - val_loss: 0.1136 - val_acc: 0.9521\n",
      "Epoch 27/100\n",
      "49812/49812 [==============================] - 3s 70us/sample - loss: 0.1459 - acc: 0.9471 - val_loss: 0.1107 - val_acc: 0.9542\n",
      "Epoch 28/100\n",
      "49812/49812 [==============================] - 3s 70us/sample - loss: 0.1440 - acc: 0.9474 - val_loss: 0.1090 - val_acc: 0.9554\n",
      "Epoch 29/100\n",
      "49812/49812 [==============================] - 3s 62us/sample - loss: 0.1452 - acc: 0.9485 - val_loss: 0.1122 - val_acc: 0.9546\n",
      "Epoch 30/100\n",
      "49812/49812 [==============================] - 3s 60us/sample - loss: 0.1462 - acc: 0.9484 - val_loss: 0.1086 - val_acc: 0.9566\n",
      "Epoch 31/100\n",
      "49812/49812 [==============================] - 3s 56us/sample - loss: 0.1404 - acc: 0.9494 - val_loss: 0.1107 - val_acc: 0.9574\n",
      "Epoch 32/100\n",
      "49812/49812 [==============================] - 3s 54us/sample - loss: 0.1389 - acc: 0.9506 - val_loss: 0.1074 - val_acc: 0.9554\n",
      "Epoch 33/100\n",
      "49812/49812 [==============================] - 3s 55us/sample - loss: 0.1362 - acc: 0.9516 - val_loss: 0.1103 - val_acc: 0.9568\n",
      "Epoch 34/100\n",
      "49812/49812 [==============================] - 3s 55us/sample - loss: 0.1425 - acc: 0.9493 - val_loss: 0.1071 - val_acc: 0.9579\n",
      "Epoch 35/100\n",
      "49812/49812 [==============================] - 3s 56us/sample - loss: 0.1370 - acc: 0.9501 - val_loss: 0.1142 - val_acc: 0.9537\n",
      "Epoch 36/100\n",
      "49812/49812 [==============================] - 3s 55us/sample - loss: 0.1367 - acc: 0.9504 - val_loss: 0.1092 - val_acc: 0.9570\n",
      "Epoch 37/100\n",
      "49812/49812 [==============================] - 3s 55us/sample - loss: 0.1353 - acc: 0.9505 - val_loss: 0.1103 - val_acc: 0.9551\n",
      "Epoch 38/100\n",
      "49812/49812 [==============================] - 3s 55us/sample - loss: 0.1345 - acc: 0.9513 - val_loss: 0.1154 - val_acc: 0.9565\n",
      "Epoch 39/100\n",
      "49812/49812 [==============================] - 3s 55us/sample - loss: 0.1355 - acc: 0.9506 - val_loss: 0.1100 - val_acc: 0.9561\n",
      "Epoch 40/100\n",
      "49812/49812 [==============================] - 3s 55us/sample - loss: 0.1310 - acc: 0.9520 - val_loss: 0.1154 - val_acc: 0.9528\n",
      "Epoch 41/100\n",
      "49812/49812 [==============================] - 3s 55us/sample - loss: 0.1327 - acc: 0.9526 - val_loss: 0.1089 - val_acc: 0.9537\n",
      "Epoch 42/100\n",
      "49812/49812 [==============================] - 3s 56us/sample - loss: 0.1305 - acc: 0.9524 - val_loss: 0.1050 - val_acc: 0.9586\n",
      "Epoch 43/100\n",
      "49812/49812 [==============================] - 3s 55us/sample - loss: 0.1294 - acc: 0.9538 - val_loss: 0.1096 - val_acc: 0.9554\n",
      "Epoch 44/100\n",
      "49812/49812 [==============================] - 3s 55us/sample - loss: 0.1291 - acc: 0.9537 - val_loss: 0.1026 - val_acc: 0.9595\n",
      "Epoch 45/100\n",
      "49812/49812 [==============================] - 3s 55us/sample - loss: 0.1270 - acc: 0.9538 - val_loss: 0.1077 - val_acc: 0.9561\n",
      "Epoch 46/100\n",
      "49812/49812 [==============================] - 3s 55us/sample - loss: 0.1300 - acc: 0.9528 - val_loss: 0.1129 - val_acc: 0.9534\n",
      "Epoch 47/100\n",
      "49812/49812 [==============================] - 3s 58us/sample - loss: 0.1304 - acc: 0.9535 - val_loss: 0.1142 - val_acc: 0.9500\n",
      "Epoch 48/100\n",
      "49812/49812 [==============================] - 3s 55us/sample - loss: 0.1271 - acc: 0.9542 - val_loss: 0.1065 - val_acc: 0.9586\n",
      "Epoch 49/100\n",
      "49812/49812 [==============================] - 3s 55us/sample - loss: 0.1251 - acc: 0.9544 - val_loss: 0.1114 - val_acc: 0.9523\n",
      "Epoch 50/100\n",
      "49812/49812 [==============================] - 3s 55us/sample - loss: 0.1249 - acc: 0.9549 - val_loss: 0.1074 - val_acc: 0.9574\n",
      "Epoch 51/100\n",
      "49812/49812 [==============================] - 3s 57us/sample - loss: 0.1244 - acc: 0.9544 - val_loss: 0.1094 - val_acc: 0.9562\n",
      "Epoch 52/100\n",
      "49812/49812 [==============================] - 3s 56us/sample - loss: 0.1234 - acc: 0.9561 - val_loss: 0.1117 - val_acc: 0.9577\n",
      "Epoch 53/100\n",
      "49812/49812 [==============================] - 3s 56us/sample - loss: 0.1234 - acc: 0.9554 - val_loss: 0.1151 - val_acc: 0.9531\n",
      "Epoch 54/100\n",
      "49812/49812 [==============================] - 3s 55us/sample - loss: 0.1228 - acc: 0.9564 - val_loss: 0.1057 - val_acc: 0.9579\n",
      "Epoch 55/100\n",
      "49812/49812 [==============================] - 3s 55us/sample - loss: 0.1215 - acc: 0.9559 - val_loss: 0.1055 - val_acc: 0.9588\n",
      "Epoch 56/100\n",
      "49812/49812 [==============================] - 3s 55us/sample - loss: 0.1198 - acc: 0.9575 - val_loss: 0.1101 - val_acc: 0.9548\n",
      "Epoch 57/100\n",
      "49812/49812 [==============================] - 3s 55us/sample - loss: 0.1199 - acc: 0.9569 - val_loss: 0.1101 - val_acc: 0.9570\n",
      "Epoch 58/100\n",
      "49812/49812 [==============================] - 3s 55us/sample - loss: 0.1195 - acc: 0.9559 - val_loss: 0.1099 - val_acc: 0.9585\n",
      "Epoch 59/100\n",
      "49812/49812 [==============================] - 3s 55us/sample - loss: 0.1200 - acc: 0.9566 - val_loss: 0.1117 - val_acc: 0.9551\n",
      "Epoch 60/100\n",
      "49812/49812 [==============================] - 3s 55us/sample - loss: 0.1226 - acc: 0.9557 - val_loss: 0.1062 - val_acc: 0.9595\n",
      "Epoch 61/100\n",
      "49812/49812 [==============================] - 3s 55us/sample - loss: 0.1202 - acc: 0.9568 - val_loss: 0.1044 - val_acc: 0.9599\n",
      "Epoch 62/100\n",
      "49812/49812 [==============================] - 3s 55us/sample - loss: 0.1188 - acc: 0.9573 - val_loss: 0.1074 - val_acc: 0.9615\n",
      "Epoch 63/100\n",
      "49812/49812 [==============================] - 3s 55us/sample - loss: 0.1164 - acc: 0.9585 - val_loss: 0.1066 - val_acc: 0.9587\n",
      "Epoch 64/100\n",
      "49812/49812 [==============================] - 3s 55us/sample - loss: 0.1167 - acc: 0.9589 - val_loss: 0.1046 - val_acc: 0.9605\n",
      "Epoch 65/100\n",
      "49812/49812 [==============================] - 3s 56us/sample - loss: 0.1168 - acc: 0.9571 - val_loss: 0.1085 - val_acc: 0.9600\n",
      "Epoch 66/100\n",
      "49812/49812 [==============================] - 3s 55us/sample - loss: 0.1153 - acc: 0.9586 - val_loss: 0.1143 - val_acc: 0.9557\n",
      "Epoch 67/100\n",
      "49812/49812 [==============================] - 3s 55us/sample - loss: 0.1131 - acc: 0.9596 - val_loss: 0.1057 - val_acc: 0.9582\n",
      "Epoch 68/100\n",
      "49812/49812 [==============================] - 3s 55us/sample - loss: 0.1146 - acc: 0.9591 - val_loss: 0.1097 - val_acc: 0.9566\n",
      "Epoch 69/100\n",
      "49812/49812 [==============================] - 3s 55us/sample - loss: 0.1145 - acc: 0.9594 - val_loss: 0.1037 - val_acc: 0.9616\n",
      "Epoch 70/100\n",
      "49812/49812 [==============================] - 3s 55us/sample - loss: 0.1205 - acc: 0.9571 - val_loss: 0.1085 - val_acc: 0.9576\n",
      "Epoch 71/100\n",
      "49812/49812 [==============================] - 3s 55us/sample - loss: 0.1157 - acc: 0.9599 - val_loss: 0.1066 - val_acc: 0.9590\n",
      "Epoch 72/100\n",
      "49812/49812 [==============================] - 3s 55us/sample - loss: 0.1141 - acc: 0.9583 - val_loss: 0.1097 - val_acc: 0.9585\n",
      "Epoch 73/100\n",
      "49812/49812 [==============================] - 3s 55us/sample - loss: 0.1141 - acc: 0.9586 - val_loss: 0.1070 - val_acc: 0.9596\n",
      "Epoch 74/100\n",
      "49812/49812 [==============================] - 3s 55us/sample - loss: 0.1097 - acc: 0.9600 - val_loss: 0.1060 - val_acc: 0.9586\n",
      "Epoch 75/100\n",
      "49812/49812 [==============================] - 3s 54us/sample - loss: 0.1154 - acc: 0.9590 - val_loss: 0.1057 - val_acc: 0.9616\n",
      "Epoch 76/100\n",
      "49812/49812 [==============================] - 3s 56us/sample - loss: 0.1126 - acc: 0.9602 - val_loss: 0.1056 - val_acc: 0.9603\n",
      "Epoch 77/100\n",
      "49812/49812 [==============================] - 3s 56us/sample - loss: 0.1154 - acc: 0.9586 - val_loss: 0.1169 - val_acc: 0.9533\n",
      "Epoch 78/100\n",
      "49812/49812 [==============================] - 3s 55us/sample - loss: 0.1126 - acc: 0.9605 - val_loss: 0.1048 - val_acc: 0.9603\n",
      "Epoch 79/100\n",
      "49812/49812 [==============================] - 3s 55us/sample - loss: 0.1138 - acc: 0.9601 - val_loss: 0.1124 - val_acc: 0.9545\n",
      "Epoch 80/100\n",
      "49812/49812 [==============================] - 3s 55us/sample - loss: 0.1101 - acc: 0.9610 - val_loss: 0.1039 - val_acc: 0.9608\n",
      "Epoch 81/100\n",
      "49812/49812 [==============================] - 3s 55us/sample - loss: 0.1082 - acc: 0.9609 - val_loss: 0.1040 - val_acc: 0.9606\n",
      "Epoch 82/100\n",
      "49812/49812 [==============================] - 3s 55us/sample - loss: 0.1110 - acc: 0.9596 - val_loss: 0.1170 - val_acc: 0.9529\n",
      "Epoch 83/100\n",
      "49812/49812 [==============================] - 3s 55us/sample - loss: 0.1087 - acc: 0.9600 - val_loss: 0.1042 - val_acc: 0.9610\n",
      "Epoch 84/100\n",
      "49812/49812 [==============================] - 3s 55us/sample - loss: 0.1080 - acc: 0.9619 - val_loss: 0.1209 - val_acc: 0.9501\n",
      "Epoch 85/100\n",
      "49812/49812 [==============================] - 3s 55us/sample - loss: 0.1075 - acc: 0.9618 - val_loss: 0.1012 - val_acc: 0.9618\n",
      "Epoch 86/100\n",
      "49812/49812 [==============================] - 3s 55us/sample - loss: 0.1108 - acc: 0.9598 - val_loss: 0.1086 - val_acc: 0.9593\n",
      "Epoch 87/100\n",
      "49812/49812 [==============================] - 3s 56us/sample - loss: 0.1066 - acc: 0.9624 - val_loss: 0.1137 - val_acc: 0.9589\n",
      "Epoch 88/100\n",
      "49812/49812 [==============================] - 3s 56us/sample - loss: 0.1057 - acc: 0.9627 - val_loss: 0.1022 - val_acc: 0.9611\n",
      "Epoch 89/100\n",
      "49812/49812 [==============================] - 3s 55us/sample - loss: 0.1073 - acc: 0.9618 - val_loss: 0.1094 - val_acc: 0.9602\n",
      "Epoch 90/100\n",
      "49812/49812 [==============================] - 3s 55us/sample - loss: 0.1078 - acc: 0.9619 - val_loss: 0.1056 - val_acc: 0.9592\n",
      "Epoch 91/100\n",
      "49812/49812 [==============================] - 3s 55us/sample - loss: 0.1070 - acc: 0.9623 - val_loss: 0.1037 - val_acc: 0.9627\n",
      "Epoch 92/100\n",
      "49812/49812 [==============================] - 3s 55us/sample - loss: 0.1061 - acc: 0.9633 - val_loss: 0.1128 - val_acc: 0.9558\n",
      "Epoch 93/100\n",
      "49812/49812 [==============================] - 3s 55us/sample - loss: 0.1040 - acc: 0.9629 - val_loss: 0.1078 - val_acc: 0.9588\n",
      "Epoch 94/100\n",
      "49812/49812 [==============================] - 3s 57us/sample - loss: 0.1081 - acc: 0.9614 - val_loss: 0.1064 - val_acc: 0.9597\n",
      "Epoch 95/100\n",
      "49812/49812 [==============================] - 3s 57us/sample - loss: 0.1071 - acc: 0.9612 - val_loss: 0.1046 - val_acc: 0.9623\n",
      "Epoch 96/100\n",
      "49812/49812 [==============================] - 3s 55us/sample - loss: 0.1047 - acc: 0.9622 - val_loss: 0.1081 - val_acc: 0.9605\n",
      "Epoch 97/100\n",
      "49812/49812 [==============================] - 3s 55us/sample - loss: 0.1069 - acc: 0.9620 - val_loss: 0.1074 - val_acc: 0.9606\n",
      "Epoch 98/100\n",
      "49812/49812 [==============================] - 3s 55us/sample - loss: 0.1053 - acc: 0.9621 - val_loss: 0.1048 - val_acc: 0.9611\n",
      "Epoch 99/100\n",
      "49812/49812 [==============================] - 3s 55us/sample - loss: 0.1070 - acc: 0.9614 - val_loss: 0.1098 - val_acc: 0.9577\n",
      "Epoch 100/100\n",
      "49812/49812 [==============================] - 3s 57us/sample - loss: 0.1047 - acc: 0.9620 - val_loss: 0.1067 - val_acc: 0.9599\n",
      "Score for fold 1: Accuracy of 95.92407014839083%\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Train on 49812 samples, validate on 12454 samples\n",
      "Epoch 1/100\n",
      "49812/49812 [==============================] - 10s 201us/sample - loss: 0.3953 - acc: 0.8318 - val_loss: 0.1815 - val_acc: 0.9295\n",
      "Epoch 2/100\n",
      "49812/49812 [==============================] - 7s 133us/sample - loss: 0.2530 - acc: 0.9090 - val_loss: 0.1655 - val_acc: 0.9337\n",
      "Epoch 3/100\n",
      "49812/49812 [==============================] - 5s 107us/sample - loss: 0.2242 - acc: 0.9207 - val_loss: 0.1437 - val_acc: 0.9444\n",
      "Epoch 4/100\n",
      "49812/49812 [==============================] - 5s 98us/sample - loss: 0.2125 - acc: 0.9252 - val_loss: 0.1386 - val_acc: 0.9453\n",
      "Epoch 5/100\n",
      "49812/49812 [==============================] - 5s 94us/sample - loss: 0.1971 - acc: 0.9288 - val_loss: 0.1348 - val_acc: 0.9473\n",
      "Epoch 6/100\n",
      "49812/49812 [==============================] - 5s 91us/sample - loss: 0.1908 - acc: 0.9317 - val_loss: 0.1326 - val_acc: 0.9485\n",
      "Epoch 7/100\n",
      "49812/49812 [==============================] - 5s 91us/sample - loss: 0.1850 - acc: 0.9341 - val_loss: 0.1294 - val_acc: 0.9493\n",
      "Epoch 8/100\n",
      "49812/49812 [==============================] - 5s 91us/sample - loss: 0.1791 - acc: 0.9360 - val_loss: 0.1234 - val_acc: 0.9511\n",
      "Epoch 9/100\n",
      "49812/49812 [==============================] - 4s 87us/sample - loss: 0.1747 - acc: 0.9370 - val_loss: 0.1283 - val_acc: 0.9480\n",
      "Epoch 10/100\n",
      "49812/49812 [==============================] - 3s 68us/sample - loss: 0.1735 - acc: 0.9374 - val_loss: 0.1225 - val_acc: 0.9522\n",
      "Epoch 11/100\n",
      "49812/49812 [==============================] - 3s 65us/sample - loss: 0.1682 - acc: 0.9393 - val_loss: 0.1249 - val_acc: 0.9505\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49812/49812 [==============================] - 3s 66us/sample - loss: 0.1633 - acc: 0.9411 - val_loss: 0.1251 - val_acc: 0.9522\n",
      "Epoch 13/100\n",
      "49812/49812 [==============================] - 3s 65us/sample - loss: 0.1646 - acc: 0.9397 - val_loss: 0.1181 - val_acc: 0.9549\n",
      "Epoch 14/100\n",
      "49812/49812 [==============================] - 3s 64us/sample - loss: 0.1574 - acc: 0.9418 - val_loss: 0.1239 - val_acc: 0.9503\n",
      "Epoch 15/100\n",
      "49812/49812 [==============================] - 3s 65us/sample - loss: 0.1581 - acc: 0.9429 - val_loss: 0.1162 - val_acc: 0.9542\n",
      "Epoch 16/100\n",
      "49812/49812 [==============================] - 3s 64us/sample - loss: 0.1580 - acc: 0.9432 - val_loss: 0.1286 - val_acc: 0.9508\n",
      "Epoch 17/100\n",
      "49812/49812 [==============================] - 3s 65us/sample - loss: 0.1562 - acc: 0.9441 - val_loss: 0.1207 - val_acc: 0.9533\n",
      "Epoch 18/100\n",
      "49812/49812 [==============================] - 3s 65us/sample - loss: 0.1554 - acc: 0.9427 - val_loss: 0.1137 - val_acc: 0.9549\n",
      "Epoch 19/100\n",
      "49812/49812 [==============================] - 3s 64us/sample - loss: 0.1527 - acc: 0.9437 - val_loss: 0.1165 - val_acc: 0.9557\n",
      "Epoch 20/100\n",
      "49812/49812 [==============================] - 3s 64us/sample - loss: 0.1477 - acc: 0.9464 - val_loss: 0.1114 - val_acc: 0.9564\n",
      "Epoch 21/100\n",
      "49812/49812 [==============================] - 3s 65us/sample - loss: 0.1487 - acc: 0.9472 - val_loss: 0.1136 - val_acc: 0.9567\n",
      "Epoch 22/100\n",
      "49812/49812 [==============================] - 3s 65us/sample - loss: 0.1488 - acc: 0.9453 - val_loss: 0.1114 - val_acc: 0.9547\n",
      "Epoch 23/100\n",
      "49812/49812 [==============================] - 3s 65us/sample - loss: 0.1422 - acc: 0.9484 - val_loss: 0.1101 - val_acc: 0.9574\n",
      "Epoch 24/100\n",
      "49812/49812 [==============================] - 3s 64us/sample - loss: 0.1435 - acc: 0.9490 - val_loss: 0.1147 - val_acc: 0.9567\n",
      "Epoch 25/100\n",
      "49812/49812 [==============================] - 3s 65us/sample - loss: 0.1429 - acc: 0.9479 - val_loss: 0.1064 - val_acc: 0.9580\n",
      "Epoch 26/100\n",
      "49812/49812 [==============================] - 3s 65us/sample - loss: 0.1418 - acc: 0.9489 - val_loss: 0.1094 - val_acc: 0.9573\n",
      "Epoch 27/100\n",
      "49812/49812 [==============================] - 3s 61us/sample - loss: 0.1380 - acc: 0.9507 - val_loss: 0.1136 - val_acc: 0.9562\n",
      "Epoch 28/100\n",
      "49812/49812 [==============================] - 3s 59us/sample - loss: 0.1422 - acc: 0.9474 - val_loss: 0.1097 - val_acc: 0.9584\n",
      "Epoch 29/100\n",
      "49812/49812 [==============================] - 3s 59us/sample - loss: 0.1353 - acc: 0.9508 - val_loss: 0.1055 - val_acc: 0.9586\n",
      "Epoch 30/100\n",
      "49812/49812 [==============================] - 3s 59us/sample - loss: 0.1377 - acc: 0.9503 - val_loss: 0.1062 - val_acc: 0.9585\n",
      "Epoch 31/100\n",
      "49812/49812 [==============================] - 3s 59us/sample - loss: 0.1351 - acc: 0.9508 - val_loss: 0.1063 - val_acc: 0.9595\n",
      "Epoch 32/100\n",
      "49812/49812 [==============================] - 3s 59us/sample - loss: 0.1336 - acc: 0.9517 - val_loss: 0.1059 - val_acc: 0.9586\n",
      "Epoch 33/100\n",
      "49812/49812 [==============================] - 3s 59us/sample - loss: 0.1352 - acc: 0.9509 - val_loss: 0.1066 - val_acc: 0.9579\n",
      "Epoch 34/100\n",
      "49812/49812 [==============================] - 3s 59us/sample - loss: 0.1381 - acc: 0.9500 - val_loss: 0.1081 - val_acc: 0.9582\n",
      "Epoch 35/100\n",
      "49812/49812 [==============================] - 3s 59us/sample - loss: 0.1304 - acc: 0.9531 - val_loss: 0.1088 - val_acc: 0.9568\n",
      "Epoch 36/100\n",
      "49812/49812 [==============================] - 3s 59us/sample - loss: 0.1303 - acc: 0.9524 - val_loss: 0.1064 - val_acc: 0.9586\n",
      "Epoch 37/100\n",
      "49812/49812 [==============================] - 3s 59us/sample - loss: 0.1278 - acc: 0.9529 - val_loss: 0.1110 - val_acc: 0.9583\n",
      "Epoch 38/100\n",
      "49812/49812 [==============================] - 3s 59us/sample - loss: 0.1304 - acc: 0.9519 - val_loss: 0.1038 - val_acc: 0.9602\n",
      "Epoch 39/100\n",
      "49812/49812 [==============================] - 3s 59us/sample - loss: 0.1324 - acc: 0.9514 - val_loss: 0.1057 - val_acc: 0.9595\n",
      "Epoch 40/100\n",
      "49812/49812 [==============================] - 3s 59us/sample - loss: 0.1290 - acc: 0.9532 - val_loss: 0.1069 - val_acc: 0.9580\n",
      "Epoch 41/100\n",
      "49812/49812 [==============================] - 3s 59us/sample - loss: 0.1299 - acc: 0.9528 - val_loss: 0.1062 - val_acc: 0.9593\n",
      "Epoch 42/100\n",
      "49812/49812 [==============================] - 3s 60us/sample - loss: 0.1248 - acc: 0.9542 - val_loss: 0.1040 - val_acc: 0.9598\n",
      "Epoch 43/100\n",
      "49812/49812 [==============================] - 3s 59us/sample - loss: 0.1265 - acc: 0.9529 - val_loss: 0.1093 - val_acc: 0.9570\n",
      "Epoch 44/100\n",
      "49812/49812 [==============================] - 3s 58us/sample - loss: 0.1252 - acc: 0.9543 - val_loss: 0.1046 - val_acc: 0.9597\n",
      "Epoch 45/100\n",
      "49812/49812 [==============================] - 3s 59us/sample - loss: 0.1247 - acc: 0.9535 - val_loss: 0.1057 - val_acc: 0.9583\n",
      "Epoch 46/100\n",
      "49812/49812 [==============================] - 3s 59us/sample - loss: 0.1227 - acc: 0.9562 - val_loss: 0.1031 - val_acc: 0.9604\n",
      "Epoch 47/100\n",
      "49812/49812 [==============================] - 3s 59us/sample - loss: 0.1209 - acc: 0.9558 - val_loss: 0.1042 - val_acc: 0.9598\n",
      "Epoch 48/100\n",
      "49812/49812 [==============================] - 3s 59us/sample - loss: 0.1229 - acc: 0.9552 - val_loss: 0.1073 - val_acc: 0.9594\n",
      "Epoch 49/100\n",
      "49812/49812 [==============================] - 3s 59us/sample - loss: 0.1223 - acc: 0.9558 - val_loss: 0.1085 - val_acc: 0.9566\n",
      "Epoch 50/100\n",
      "49812/49812 [==============================] - 3s 59us/sample - loss: 0.1208 - acc: 0.9560 - val_loss: 0.1051 - val_acc: 0.9598\n",
      "Epoch 51/100\n",
      "49812/49812 [==============================] - 3s 59us/sample - loss: 0.1198 - acc: 0.9564 - val_loss: 0.1033 - val_acc: 0.9599\n",
      "Epoch 52/100\n",
      "49812/49812 [==============================] - 3s 60us/sample - loss: 0.1217 - acc: 0.9556 - val_loss: 0.1031 - val_acc: 0.9601\n",
      "Epoch 53/100\n",
      "49812/49812 [==============================] - 3s 59us/sample - loss: 0.1209 - acc: 0.9578 - val_loss: 0.1048 - val_acc: 0.9599\n",
      "Epoch 54/100\n",
      "49812/49812 [==============================] - 3s 59us/sample - loss: 0.1182 - acc: 0.9567 - val_loss: 0.1012 - val_acc: 0.9607\n",
      "Epoch 55/100\n",
      "49812/49812 [==============================] - 3s 59us/sample - loss: 0.1159 - acc: 0.9573 - val_loss: 0.1045 - val_acc: 0.9598\n",
      "Epoch 56/100\n",
      "49812/49812 [==============================] - 3s 59us/sample - loss: 0.1165 - acc: 0.9576 - val_loss: 0.1055 - val_acc: 0.9604\n",
      "Epoch 57/100\n",
      "49812/49812 [==============================] - 3s 59us/sample - loss: 0.1191 - acc: 0.9569 - val_loss: 0.1076 - val_acc: 0.9581\n",
      "Epoch 58/100\n",
      "49812/49812 [==============================] - 3s 62us/sample - loss: 0.1162 - acc: 0.9572 - val_loss: 0.1031 - val_acc: 0.9603\n",
      "Epoch 59/100\n",
      "49812/49812 [==============================] - 3s 60us/sample - loss: 0.1169 - acc: 0.9571 - val_loss: 0.1014 - val_acc: 0.9621\n",
      "Epoch 60/100\n",
      "49812/49812 [==============================] - 3s 59us/sample - loss: 0.1188 - acc: 0.9576 - val_loss: 0.1006 - val_acc: 0.9622\n",
      "Epoch 61/100\n",
      "49812/49812 [==============================] - 3s 59us/sample - loss: 0.1153 - acc: 0.9580 - val_loss: 0.1043 - val_acc: 0.9596\n",
      "Epoch 62/100\n",
      "49812/49812 [==============================] - 3s 59us/sample - loss: 0.1140 - acc: 0.9589 - val_loss: 0.1155 - val_acc: 0.9569\n",
      "Epoch 63/100\n",
      "49812/49812 [==============================] - 3s 59us/sample - loss: 0.1148 - acc: 0.9584 - val_loss: 0.1018 - val_acc: 0.9597\n",
      "Epoch 64/100\n",
      "49812/49812 [==============================] - 3s 60us/sample - loss: 0.1136 - acc: 0.9587 - val_loss: 0.1051 - val_acc: 0.9595\n",
      "Epoch 65/100\n",
      "49812/49812 [==============================] - 3s 59us/sample - loss: 0.1160 - acc: 0.9591 - val_loss: 0.1051 - val_acc: 0.9604\n",
      "Epoch 66/100\n",
      "49812/49812 [==============================] - 3s 59us/sample - loss: 0.1133 - acc: 0.9589 - val_loss: 0.1048 - val_acc: 0.9604\n",
      "Epoch 67/100\n",
      "49812/49812 [==============================] - 3s 59us/sample - loss: 0.1123 - acc: 0.9597 - val_loss: 0.1030 - val_acc: 0.9615\n",
      "Epoch 68/100\n",
      "49812/49812 [==============================] - 3s 60us/sample - loss: 0.1109 - acc: 0.9591 - val_loss: 0.1045 - val_acc: 0.9617\n",
      "Epoch 69/100\n",
      "49812/49812 [==============================] - 3s 59us/sample - loss: 0.1129 - acc: 0.9591 - val_loss: 0.1028 - val_acc: 0.9607\n",
      "Epoch 70/100\n",
      "49812/49812 [==============================] - 3s 59us/sample - loss: 0.1105 - acc: 0.9592 - val_loss: 0.1047 - val_acc: 0.9621\n",
      "Epoch 71/100\n",
      "49812/49812 [==============================] - 3s 58us/sample - loss: 0.1115 - acc: 0.9596 - val_loss: 0.1054 - val_acc: 0.9604\n",
      "Epoch 72/100\n",
      "49812/49812 [==============================] - 3s 59us/sample - loss: 0.1135 - acc: 0.9589 - val_loss: 0.1049 - val_acc: 0.9599\n",
      "Epoch 73/100\n",
      "49812/49812 [==============================] - 3s 59us/sample - loss: 0.1118 - acc: 0.9598 - val_loss: 0.1033 - val_acc: 0.9595\n",
      "Epoch 74/100\n",
      "49812/49812 [==============================] - 3s 59us/sample - loss: 0.1114 - acc: 0.9602 - val_loss: 0.1017 - val_acc: 0.9619\n",
      "Epoch 75/100\n",
      "49812/49812 [==============================] - 3s 59us/sample - loss: 0.1099 - acc: 0.9595 - val_loss: 0.0987 - val_acc: 0.9627\n",
      "Epoch 76/100\n",
      "49812/49812 [==============================] - 3s 61us/sample - loss: 0.1089 - acc: 0.9609 - val_loss: 0.1024 - val_acc: 0.9607\n",
      "Epoch 77/100\n",
      "49812/49812 [==============================] - 3s 60us/sample - loss: 0.1091 - acc: 0.9614 - val_loss: 0.1037 - val_acc: 0.9616\n",
      "Epoch 78/100\n",
      "49812/49812 [==============================] - 3s 59us/sample - loss: 0.1075 - acc: 0.9610 - val_loss: 0.1042 - val_acc: 0.9613\n",
      "Epoch 79/100\n",
      "49812/49812 [==============================] - 3s 59us/sample - loss: 0.1100 - acc: 0.9604 - val_loss: 0.1044 - val_acc: 0.9618\n",
      "Epoch 80/100\n",
      "49812/49812 [==============================] - 3s 59us/sample - loss: 0.1082 - acc: 0.9612 - val_loss: 0.1063 - val_acc: 0.9596\n",
      "Epoch 81/100\n",
      "49812/49812 [==============================] - 3s 59us/sample - loss: 0.1058 - acc: 0.9617 - val_loss: 0.1031 - val_acc: 0.9623\n",
      "Epoch 82/100\n",
      "49812/49812 [==============================] - 3s 60us/sample - loss: 0.1122 - acc: 0.9600 - val_loss: 0.1051 - val_acc: 0.9588\n",
      "Epoch 83/100\n",
      "49812/49812 [==============================] - 3s 59us/sample - loss: 0.1082 - acc: 0.9609 - val_loss: 0.1058 - val_acc: 0.9611\n",
      "Epoch 84/100\n",
      "49812/49812 [==============================] - 3s 58us/sample - loss: 0.1046 - acc: 0.9619 - val_loss: 0.1024 - val_acc: 0.9610\n",
      "Epoch 85/100\n",
      "49812/49812 [==============================] - 3s 58us/sample - loss: 0.1077 - acc: 0.9615 - val_loss: 0.1067 - val_acc: 0.9591\n",
      "Epoch 86/100\n",
      "49812/49812 [==============================] - 3s 59us/sample - loss: 0.1053 - acc: 0.9624 - val_loss: 0.1050 - val_acc: 0.9626\n",
      "Epoch 87/100\n",
      "49812/49812 [==============================] - 3s 59us/sample - loss: 0.1061 - acc: 0.9620 - val_loss: 0.1023 - val_acc: 0.9619\n",
      "Epoch 88/100\n",
      "49812/49812 [==============================] - 3s 59us/sample - loss: 0.1018 - acc: 0.9635 - val_loss: 0.1092 - val_acc: 0.9582\n",
      "Epoch 89/100\n",
      "49812/49812 [==============================] - 3s 59us/sample - loss: 0.1057 - acc: 0.9625 - val_loss: 0.1053 - val_acc: 0.9608\n",
      "Epoch 90/100\n",
      "49812/49812 [==============================] - 3s 59us/sample - loss: 0.1037 - acc: 0.9629 - val_loss: 0.1080 - val_acc: 0.9595\n",
      "Epoch 91/100\n",
      "49812/49812 [==============================] - 3s 59us/sample - loss: 0.1026 - acc: 0.9635 - val_loss: 0.1057 - val_acc: 0.9616\n",
      "Epoch 92/100\n",
      "49812/49812 [==============================] - 3s 59us/sample - loss: 0.1034 - acc: 0.9621 - val_loss: 0.1091 - val_acc: 0.9630\n",
      "Epoch 93/100\n",
      "49812/49812 [==============================] - 3s 59us/sample - loss: 0.1034 - acc: 0.9626 - val_loss: 0.1044 - val_acc: 0.9620\n",
      "Epoch 94/100\n",
      "49812/49812 [==============================] - 3s 59us/sample - loss: 0.1060 - acc: 0.9614 - val_loss: 0.1037 - val_acc: 0.9626\n",
      "Epoch 95/100\n",
      "49812/49812 [==============================] - 3s 59us/sample - loss: 0.1047 - acc: 0.9617 - val_loss: 0.1028 - val_acc: 0.9603\n",
      "Epoch 96/100\n",
      "49812/49812 [==============================] - 3s 59us/sample - loss: 0.1037 - acc: 0.9627 - val_loss: 0.1071 - val_acc: 0.9586\n",
      "Epoch 97/100\n",
      "49812/49812 [==============================] - 4s 75us/sample - loss: 0.1031 - acc: 0.9623 - val_loss: 0.1052 - val_acc: 0.9615\n",
      "Epoch 98/100\n",
      "49812/49812 [==============================] - 3s 66us/sample - loss: 0.0998 - acc: 0.9634 - val_loss: 0.1064 - val_acc: 0.9619\n",
      "Epoch 99/100\n",
      "49812/49812 [==============================] - 3s 63us/sample - loss: 0.0999 - acc: 0.9644 - val_loss: 0.1068 - val_acc: 0.9604\n",
      "Epoch 100/100\n",
      "49812/49812 [==============================] - 3s 65us/sample - loss: 0.1030 - acc: 0.9624 - val_loss: 0.1033 - val_acc: 0.9618\n",
      "Score for fold 2: Accuracy of 96.39622277895549%\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Train on 49813 samples, validate on 12454 samples\n",
      "Epoch 1/100\n",
      "49813/49813 [==============================] - 10s 197us/sample - loss: 0.3508 - acc: 0.8590 - val_loss: 0.1791 - val_acc: 0.9321\n",
      "Epoch 2/100\n",
      "49813/49813 [==============================] - 5s 107us/sample - loss: 0.2400 - acc: 0.9143 - val_loss: 0.1551 - val_acc: 0.9378\n",
      "Epoch 3/100\n",
      "49813/49813 [==============================] - 4s 82us/sample - loss: 0.2113 - acc: 0.9248 - val_loss: 0.1413 - val_acc: 0.9444\n",
      "Epoch 4/100\n",
      "49813/49813 [==============================] - 4s 79us/sample - loss: 0.2006 - acc: 0.9283 - val_loss: 0.1348 - val_acc: 0.9486\n",
      "Epoch 5/100\n",
      "49813/49813 [==============================] - 4s 80us/sample - loss: 0.1905 - acc: 0.9316 - val_loss: 0.1334 - val_acc: 0.9468\n",
      "Epoch 6/100\n",
      "49813/49813 [==============================] - 4s 84us/sample - loss: 0.1837 - acc: 0.9340 - val_loss: 0.1306 - val_acc: 0.9489\n",
      "Epoch 7/100\n",
      "49813/49813 [==============================] - 3s 63us/sample - loss: 0.1770 - acc: 0.9357 - val_loss: 0.1318 - val_acc: 0.9471\n",
      "Epoch 8/100\n",
      "49813/49813 [==============================] - 3s 66us/sample - loss: 0.1789 - acc: 0.9345 - val_loss: 0.1275 - val_acc: 0.9516\n",
      "Epoch 9/100\n",
      "49813/49813 [==============================] - 3s 68us/sample - loss: 0.1680 - acc: 0.9394 - val_loss: 0.1231 - val_acc: 0.9525\n",
      "Epoch 10/100\n",
      "49813/49813 [==============================] - 3s 66us/sample - loss: 0.1682 - acc: 0.9381 - val_loss: 0.1189 - val_acc: 0.9534\n",
      "Epoch 11/100\n",
      "49813/49813 [==============================] - 3s 64us/sample - loss: 0.1621 - acc: 0.9413 - val_loss: 0.1332 - val_acc: 0.9513\n",
      "Epoch 12/100\n",
      "49813/49813 [==============================] - 3s 65us/sample - loss: 0.1645 - acc: 0.9410 - val_loss: 0.1176 - val_acc: 0.9547\n",
      "Epoch 13/100\n",
      "49813/49813 [==============================] - 3s 65us/sample - loss: 0.1564 - acc: 0.9428 - val_loss: 0.1135 - val_acc: 0.9555\n",
      "Epoch 14/100\n",
      "49813/49813 [==============================] - 3s 59us/sample - loss: 0.1583 - acc: 0.9431 - val_loss: 0.1139 - val_acc: 0.9554\n",
      "Epoch 15/100\n",
      "49813/49813 [==============================] - 3s 62us/sample - loss: 0.1510 - acc: 0.9461 - val_loss: 0.1281 - val_acc: 0.9472\n",
      "Epoch 16/100\n",
      "49813/49813 [==============================] - 3s 62us/sample - loss: 0.1562 - acc: 0.9441 - val_loss: 0.1129 - val_acc: 0.9565\n",
      "Epoch 17/100\n",
      "49813/49813 [==============================] - 3s 63us/sample - loss: 0.1521 - acc: 0.9438 - val_loss: 0.1117 - val_acc: 0.9567\n",
      "Epoch 18/100\n",
      "49813/49813 [==============================] - 3s 61us/sample - loss: 0.1498 - acc: 0.9463 - val_loss: 0.1125 - val_acc: 0.9566\n",
      "Epoch 19/100\n",
      "49813/49813 [==============================] - 4s 71us/sample - loss: 0.1449 - acc: 0.9467 - val_loss: 0.1134 - val_acc: 0.9586\n",
      "Epoch 20/100\n",
      "49813/49813 [==============================] - 3s 61us/sample - loss: 0.1487 - acc: 0.9459 - val_loss: 0.1144 - val_acc: 0.9536\n",
      "Epoch 21/100\n",
      "49813/49813 [==============================] - 3s 59us/sample - loss: 0.1416 - acc: 0.9495 - val_loss: 0.1091 - val_acc: 0.9585\n",
      "Epoch 22/100\n",
      "49813/49813 [==============================] - 3s 58us/sample - loss: 0.1454 - acc: 0.9476 - val_loss: 0.1086 - val_acc: 0.9576\n",
      "Epoch 23/100\n",
      "49813/49813 [==============================] - 3s 57us/sample - loss: 0.1398 - acc: 0.9488 - val_loss: 0.1125 - val_acc: 0.9558\n",
      "Epoch 24/100\n",
      "49813/49813 [==============================] - 3s 58us/sample - loss: 0.1421 - acc: 0.9480 - val_loss: 0.1093 - val_acc: 0.9585\n",
      "Epoch 25/100\n",
      "49813/49813 [==============================] - 3s 57us/sample - loss: 0.1373 - acc: 0.9496 - val_loss: 0.1109 - val_acc: 0.9564\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49813/49813 [==============================] - 3s 62us/sample - loss: 0.1406 - acc: 0.9497 - val_loss: 0.1062 - val_acc: 0.9586\n",
      "Epoch 27/100\n",
      "49813/49813 [==============================] - 3s 63us/sample - loss: 0.1383 - acc: 0.9505 - val_loss: 0.1056 - val_acc: 0.9593\n",
      "Epoch 28/100\n",
      "49813/49813 [==============================] - 3s 62us/sample - loss: 0.1355 - acc: 0.9514 - val_loss: 0.1052 - val_acc: 0.9591\n",
      "Epoch 29/100\n",
      "49813/49813 [==============================] - 3s 61us/sample - loss: 0.1348 - acc: 0.9518 - val_loss: 0.1066 - val_acc: 0.9583\n",
      "Epoch 30/100\n",
      "49813/49813 [==============================] - 3s 61us/sample - loss: 0.1318 - acc: 0.9516 - val_loss: 0.1106 - val_acc: 0.9549\n",
      "Epoch 31/100\n",
      "49813/49813 [==============================] - 3s 68us/sample - loss: 0.1315 - acc: 0.9523 - val_loss: 0.1085 - val_acc: 0.9601\n",
      "Epoch 32/100\n",
      "49813/49813 [==============================] - 3s 61us/sample - loss: 0.1317 - acc: 0.9524 - val_loss: 0.1063 - val_acc: 0.9599\n",
      "Epoch 33/100\n",
      "49813/49813 [==============================] - 3s 60us/sample - loss: 0.1339 - acc: 0.9528 - val_loss: 0.1077 - val_acc: 0.9606\n",
      "Epoch 34/100\n",
      "49813/49813 [==============================] - 3s 60us/sample - loss: 0.1288 - acc: 0.9524 - val_loss: 0.1049 - val_acc: 0.9593\n",
      "Epoch 35/100\n",
      "49813/49813 [==============================] - 3s 60us/sample - loss: 0.1291 - acc: 0.9525 - val_loss: 0.1040 - val_acc: 0.9612\n",
      "Epoch 36/100\n",
      "49813/49813 [==============================] - 3s 60us/sample - loss: 0.1302 - acc: 0.9525 - val_loss: 0.1102 - val_acc: 0.9587\n",
      "Epoch 37/100\n",
      "49813/49813 [==============================] - 3s 59us/sample - loss: 0.1278 - acc: 0.9528 - val_loss: 0.1079 - val_acc: 0.9605\n",
      "Epoch 38/100\n",
      "49813/49813 [==============================] - 3s 60us/sample - loss: 0.1294 - acc: 0.9521 - val_loss: 0.1038 - val_acc: 0.9601\n",
      "Epoch 39/100\n",
      "49813/49813 [==============================] - 7s 132us/sample - loss: 0.1271 - acc: 0.9533 - val_loss: 0.1014 - val_acc: 0.9615\n",
      "Epoch 40/100\n",
      "49813/49813 [==============================] - 6s 126us/sample - loss: 0.1261 - acc: 0.9550 - val_loss: 0.1065 - val_acc: 0.9595\n",
      "Epoch 41/100\n",
      "49813/49813 [==============================] - 6s 123us/sample - loss: 0.1255 - acc: 0.9547 - val_loss: 0.1042 - val_acc: 0.9614\n",
      "Epoch 42/100\n",
      "49813/49813 [==============================] - 6s 116us/sample - loss: 0.1225 - acc: 0.9540 - val_loss: 0.1060 - val_acc: 0.9605\n",
      "Epoch 43/100\n",
      "49813/49813 [==============================] - 6s 116us/sample - loss: 0.1255 - acc: 0.9544 - val_loss: 0.1117 - val_acc: 0.9570\n",
      "Epoch 44/100\n",
      "49813/49813 [==============================] - 6s 115us/sample - loss: 0.1229 - acc: 0.9553 - val_loss: 0.1012 - val_acc: 0.9627\n",
      "Epoch 45/100\n",
      "49813/49813 [==============================] - 4s 84us/sample - loss: 0.1209 - acc: 0.9568 - val_loss: 0.1077 - val_acc: 0.9590\n",
      "Epoch 46/100\n",
      "49813/49813 [==============================] - 4s 77us/sample - loss: 0.1222 - acc: 0.9556 - val_loss: 0.1015 - val_acc: 0.9615\n",
      "Epoch 47/100\n",
      "49813/49813 [==============================] - 4s 72us/sample - loss: 0.1212 - acc: 0.9554 - val_loss: 0.1006 - val_acc: 0.9623\n",
      "Epoch 48/100\n",
      "49813/49813 [==============================] - 4s 76us/sample - loss: 0.1155 - acc: 0.9586 - val_loss: 0.1013 - val_acc: 0.9615\n",
      "Epoch 49/100\n",
      "49813/49813 [==============================] - 3s 62us/sample - loss: 0.1201 - acc: 0.9558 - val_loss: 0.1019 - val_acc: 0.9607\n",
      "Epoch 50/100\n",
      "49813/49813 [==============================] - 3s 62us/sample - loss: 0.1198 - acc: 0.9570 - val_loss: 0.0999 - val_acc: 0.9627\n",
      "Epoch 51/100\n",
      "49813/49813 [==============================] - 3s 60us/sample - loss: 0.1192 - acc: 0.9564 - val_loss: 0.1002 - val_acc: 0.9627\n",
      "Epoch 52/100\n",
      "49813/49813 [==============================] - 3s 60us/sample - loss: 0.1175 - acc: 0.9578 - val_loss: 0.1006 - val_acc: 0.9610\n",
      "Epoch 53/100\n",
      "49813/49813 [==============================] - 3s 60us/sample - loss: 0.1176 - acc: 0.9575 - val_loss: 0.1050 - val_acc: 0.9606\n",
      "Epoch 54/100\n",
      "49813/49813 [==============================] - 3s 60us/sample - loss: 0.1177 - acc: 0.9571 - val_loss: 0.1057 - val_acc: 0.9599\n",
      "Epoch 55/100\n",
      "49813/49813 [==============================] - 3s 60us/sample - loss: 0.1172 - acc: 0.9566 - val_loss: 0.1054 - val_acc: 0.9619\n",
      "Epoch 56/100\n",
      "49813/49813 [==============================] - 3s 60us/sample - loss: 0.1157 - acc: 0.9572 - val_loss: 0.1050 - val_acc: 0.9591\n",
      "Epoch 57/100\n",
      "49813/49813 [==============================] - 3s 60us/sample - loss: 0.1166 - acc: 0.9572 - val_loss: 0.0999 - val_acc: 0.9631\n",
      "Epoch 58/100\n",
      "49813/49813 [==============================] - 3s 60us/sample - loss: 0.1155 - acc: 0.9586 - val_loss: 0.0997 - val_acc: 0.9625\n",
      "Epoch 59/100\n",
      "49813/49813 [==============================] - 3s 60us/sample - loss: 0.1128 - acc: 0.9584 - val_loss: 0.1035 - val_acc: 0.9633\n",
      "Epoch 60/100\n",
      "49813/49813 [==============================] - 3s 62us/sample - loss: 0.1122 - acc: 0.9591 - val_loss: 0.1025 - val_acc: 0.9627\n",
      "Epoch 61/100\n",
      "49813/49813 [==============================] - 3s 61us/sample - loss: 0.1154 - acc: 0.9585 - val_loss: 0.1031 - val_acc: 0.9604\n",
      "Epoch 62/100\n",
      "49813/49813 [==============================] - 3s 63us/sample - loss: 0.1141 - acc: 0.9592 - val_loss: 0.1045 - val_acc: 0.9614\n",
      "Epoch 63/100\n",
      "49813/49813 [==============================] - 4s 71us/sample - loss: 0.1141 - acc: 0.9582 - val_loss: 0.1008 - val_acc: 0.9630\n",
      "Epoch 64/100\n",
      "49813/49813 [==============================] - 3s 62us/sample - loss: 0.1117 - acc: 0.9596 - val_loss: 0.1114 - val_acc: 0.9575\n",
      "Epoch 65/100\n",
      "49813/49813 [==============================] - 3s 62us/sample - loss: 0.1107 - acc: 0.9596 - val_loss: 0.1039 - val_acc: 0.9636\n",
      "Epoch 66/100\n",
      "49813/49813 [==============================] - 3s 62us/sample - loss: 0.1118 - acc: 0.9594 - val_loss: 0.1028 - val_acc: 0.9631\n",
      "Epoch 67/100\n",
      "49813/49813 [==============================] - 3s 60us/sample - loss: 0.1122 - acc: 0.9597 - val_loss: 0.1007 - val_acc: 0.9625\n",
      "Epoch 68/100\n",
      "49813/49813 [==============================] - 3s 60us/sample - loss: 0.1089 - acc: 0.9586 - val_loss: 0.1009 - val_acc: 0.9642\n",
      "Epoch 69/100\n",
      "49813/49813 [==============================] - 3s 60us/sample - loss: 0.1153 - acc: 0.9583 - val_loss: 0.1008 - val_acc: 0.9626\n",
      "Epoch 70/100\n",
      "49813/49813 [==============================] - 3s 60us/sample - loss: 0.1144 - acc: 0.9596 - val_loss: 0.1002 - val_acc: 0.9631\n",
      "Epoch 71/100\n",
      "49813/49813 [==============================] - 3s 60us/sample - loss: 0.1071 - acc: 0.9612 - val_loss: 0.1021 - val_acc: 0.9614\n",
      "Epoch 72/100\n",
      "49813/49813 [==============================] - 3s 60us/sample - loss: 0.1081 - acc: 0.9605 - val_loss: 0.1024 - val_acc: 0.9635\n",
      "Epoch 73/100\n",
      "49813/49813 [==============================] - 3s 60us/sample - loss: 0.1082 - acc: 0.9602 - val_loss: 0.1037 - val_acc: 0.9634\n",
      "Epoch 74/100\n",
      "49813/49813 [==============================] - 3s 60us/sample - loss: 0.1073 - acc: 0.9604 - val_loss: 0.1045 - val_acc: 0.9635\n",
      "Epoch 75/100\n",
      "49813/49813 [==============================] - 3s 60us/sample - loss: 0.1121 - acc: 0.9592 - val_loss: 0.1090 - val_acc: 0.9615\n",
      "Epoch 76/100\n",
      "49813/49813 [==============================] - 3s 60us/sample - loss: 0.1058 - acc: 0.9613 - val_loss: 0.1004 - val_acc: 0.9651\n",
      "Epoch 77/100\n",
      "49813/49813 [==============================] - 3s 60us/sample - loss: 0.1065 - acc: 0.9601 - val_loss: 0.0998 - val_acc: 0.9643\n",
      "Epoch 78/100\n",
      "49813/49813 [==============================] - 4s 72us/sample - loss: 0.1069 - acc: 0.9612 - val_loss: 0.0999 - val_acc: 0.9642\n",
      "Epoch 79/100\n",
      "49813/49813 [==============================] - 3s 61us/sample - loss: 0.1081 - acc: 0.9601 - val_loss: 0.1050 - val_acc: 0.9602\n",
      "Epoch 80/100\n",
      "49813/49813 [==============================] - 3s 61us/sample - loss: 0.1120 - acc: 0.9597 - val_loss: 0.1009 - val_acc: 0.9631\n",
      "Epoch 81/100\n",
      "49813/49813 [==============================] - 3s 62us/sample - loss: 0.1057 - acc: 0.9614 - val_loss: 0.1016 - val_acc: 0.9633\n",
      "Epoch 82/100\n",
      "49813/49813 [==============================] - 3s 60us/sample - loss: 0.1072 - acc: 0.9610 - val_loss: 0.1014 - val_acc: 0.9635\n",
      "Epoch 83/100\n",
      "49813/49813 [==============================] - 3s 60us/sample - loss: 0.1085 - acc: 0.9602 - val_loss: 0.1015 - val_acc: 0.9627\n",
      "Epoch 84/100\n",
      "49813/49813 [==============================] - 3s 58us/sample - loss: 0.1050 - acc: 0.9625 - val_loss: 0.1012 - val_acc: 0.9644\n",
      "Epoch 85/100\n",
      "49813/49813 [==============================] - 3s 58us/sample - loss: 0.1044 - acc: 0.9618 - val_loss: 0.1044 - val_acc: 0.9604\n",
      "Epoch 86/100\n",
      "49813/49813 [==============================] - 3s 58us/sample - loss: 0.1049 - acc: 0.9618 - val_loss: 0.1029 - val_acc: 0.9630\n",
      "Epoch 87/100\n",
      "49813/49813 [==============================] - 3s 59us/sample - loss: 0.1091 - acc: 0.9609 - val_loss: 0.0979 - val_acc: 0.9640\n",
      "Epoch 88/100\n",
      "49813/49813 [==============================] - 3s 59us/sample - loss: 0.1060 - acc: 0.9618 - val_loss: 0.1013 - val_acc: 0.9625\n",
      "Epoch 89/100\n",
      "49813/49813 [==============================] - 3s 58us/sample - loss: 0.1045 - acc: 0.9619 - val_loss: 0.1001 - val_acc: 0.9639\n",
      "Epoch 90/100\n",
      "49813/49813 [==============================] - 3s 58us/sample - loss: 0.1015 - acc: 0.9630 - val_loss: 0.0999 - val_acc: 0.9652\n",
      "Epoch 91/100\n",
      "49813/49813 [==============================] - 3s 59us/sample - loss: 0.1018 - acc: 0.9624 - val_loss: 0.1085 - val_acc: 0.9627\n",
      "Epoch 92/100\n",
      "49813/49813 [==============================] - 3s 58us/sample - loss: 0.1033 - acc: 0.9625 - val_loss: 0.1039 - val_acc: 0.9618\n",
      "Epoch 93/100\n",
      "49813/49813 [==============================] - 3s 59us/sample - loss: 0.1023 - acc: 0.9627 - val_loss: 0.1045 - val_acc: 0.9624\n",
      "Epoch 94/100\n",
      "49813/49813 [==============================] - 3s 59us/sample - loss: 0.1058 - acc: 0.9617 - val_loss: 0.1029 - val_acc: 0.9621\n",
      "Epoch 95/100\n",
      "49813/49813 [==============================] - 3s 58us/sample - loss: 0.1020 - acc: 0.9633 - val_loss: 0.0999 - val_acc: 0.9643\n",
      "Epoch 96/100\n",
      "49813/49813 [==============================] - 3s 58us/sample - loss: 0.1010 - acc: 0.9636 - val_loss: 0.1002 - val_acc: 0.9655\n",
      "Epoch 97/100\n",
      "49813/49813 [==============================] - 3s 58us/sample - loss: 0.1038 - acc: 0.9624 - val_loss: 0.1009 - val_acc: 0.9638\n",
      "Epoch 98/100\n",
      "49813/49813 [==============================] - 3s 59us/sample - loss: 0.1014 - acc: 0.9627 - val_loss: 0.0986 - val_acc: 0.9650\n",
      "Epoch 99/100\n",
      "49813/49813 [==============================] - 3s 59us/sample - loss: 0.1006 - acc: 0.9640 - val_loss: 0.1018 - val_acc: 0.9649\n",
      "Epoch 100/100\n",
      "49813/49813 [==============================] - 3s 58us/sample - loss: 0.0994 - acc: 0.9633 - val_loss: 0.1009 - val_acc: 0.9633\n",
      "Score for fold 3: Accuracy of 96.17441580342087%\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Train on 49813 samples, validate on 12454 samples\n",
      "Epoch 1/100\n",
      "49813/49813 [==============================] - 11s 215us/sample - loss: 0.3707 - acc: 0.8480 - val_loss: 0.1862 - val_acc: 0.9263\n",
      "Epoch 2/100\n",
      "49813/49813 [==============================] - 5s 109us/sample - loss: 0.2408 - acc: 0.9160 - val_loss: 0.1575 - val_acc: 0.9370\n",
      "Epoch 3/100\n",
      "49813/49813 [==============================] - 5s 95us/sample - loss: 0.2166 - acc: 0.9246 - val_loss: 0.1518 - val_acc: 0.9415\n",
      "Epoch 4/100\n",
      "49813/49813 [==============================] - 8s 151us/sample - loss: 0.2035 - acc: 0.9291 - val_loss: 0.1427 - val_acc: 0.9459\n",
      "Epoch 5/100\n",
      "49813/49813 [==============================] - 6s 129us/sample - loss: 0.1949 - acc: 0.9330 - val_loss: 0.1507 - val_acc: 0.9435\n",
      "Epoch 6/100\n",
      "49813/49813 [==============================] - 5s 100us/sample - loss: 0.1889 - acc: 0.9335 - val_loss: 0.1365 - val_acc: 0.9477\n",
      "Epoch 7/100\n",
      "49813/49813 [==============================] - 4s 78us/sample - loss: 0.1828 - acc: 0.9364 - val_loss: 0.1304 - val_acc: 0.9479\n",
      "Epoch 8/100\n",
      "49813/49813 [==============================] - 4s 79us/sample - loss: 0.1745 - acc: 0.9381 - val_loss: 0.1286 - val_acc: 0.9500\n",
      "Epoch 9/100\n",
      "49813/49813 [==============================] - 4s 71us/sample - loss: 0.1749 - acc: 0.9372 - val_loss: 0.1319 - val_acc: 0.9482\n",
      "Epoch 10/100\n",
      "49813/49813 [==============================] - 4s 70us/sample - loss: 0.1684 - acc: 0.9403 - val_loss: 0.1281 - val_acc: 0.9491\n",
      "Epoch 11/100\n",
      "49813/49813 [==============================] - 4s 74us/sample - loss: 0.1655 - acc: 0.9403 - val_loss: 0.1238 - val_acc: 0.9512\n",
      "Epoch 12/100\n",
      "49813/49813 [==============================] - 4s 76us/sample - loss: 0.1630 - acc: 0.9412 - val_loss: 0.1226 - val_acc: 0.9521\n",
      "Epoch 13/100\n",
      "49813/49813 [==============================] - 3s 70us/sample - loss: 0.1610 - acc: 0.9419 - val_loss: 0.1206 - val_acc: 0.9537\n",
      "Epoch 14/100\n",
      "49813/49813 [==============================] - 4s 74us/sample - loss: 0.1593 - acc: 0.9435 - val_loss: 0.1215 - val_acc: 0.9533\n",
      "Epoch 15/100\n",
      "49813/49813 [==============================] - 3s 62us/sample - loss: 0.1520 - acc: 0.9449 - val_loss: 0.1241 - val_acc: 0.9521\n",
      "Epoch 16/100\n",
      "49813/49813 [==============================] - 3s 62us/sample - loss: 0.1574 - acc: 0.9438 - val_loss: 0.1214 - val_acc: 0.9533\n",
      "Epoch 17/100\n",
      "49813/49813 [==============================] - 3s 63us/sample - loss: 0.1534 - acc: 0.9450 - val_loss: 0.1212 - val_acc: 0.9537\n",
      "Epoch 18/100\n",
      "49813/49813 [==============================] - 3s 64us/sample - loss: 0.1474 - acc: 0.9453 - val_loss: 0.1181 - val_acc: 0.9537\n",
      "Epoch 19/100\n",
      "49813/49813 [==============================] - 7s 134us/sample - loss: 0.1491 - acc: 0.9463 - val_loss: 0.1167 - val_acc: 0.9553\n",
      "Epoch 20/100\n",
      "49813/49813 [==============================] - 5s 103us/sample - loss: 0.1440 - acc: 0.9479 - val_loss: 0.1163 - val_acc: 0.9546\n",
      "Epoch 21/100\n",
      "49813/49813 [==============================] - 5s 98us/sample - loss: 0.1434 - acc: 0.9478 - val_loss: 0.1171 - val_acc: 0.9556\n",
      "Epoch 22/100\n",
      "49813/49813 [==============================] - 4s 80us/sample - loss: 0.1461 - acc: 0.9487 - val_loss: 0.1169 - val_acc: 0.9546\n",
      "Epoch 23/100\n",
      "49813/49813 [==============================] - 7s 144us/sample - loss: 0.1482 - acc: 0.9477 - val_loss: 0.1173 - val_acc: 0.9545\n",
      "Epoch 24/100\n",
      "49813/49813 [==============================] - 6s 115us/sample - loss: 0.1407 - acc: 0.9493 - val_loss: 0.1146 - val_acc: 0.9555\n",
      "Epoch 25/100\n",
      "49813/49813 [==============================] - 5s 102us/sample - loss: 0.1393 - acc: 0.9505 - val_loss: 0.1141 - val_acc: 0.9568\n",
      "Epoch 26/100\n",
      "49813/49813 [==============================] - 5s 104us/sample - loss: 0.1408 - acc: 0.9496 - val_loss: 0.1112 - val_acc: 0.9583\n",
      "Epoch 27/100\n",
      "49813/49813 [==============================] - 7s 133us/sample - loss: 0.1383 - acc: 0.9506 - val_loss: 0.1140 - val_acc: 0.9572\n",
      "Epoch 28/100\n",
      "49813/49813 [==============================] - 6s 127us/sample - loss: 0.1379 - acc: 0.9505 - val_loss: 0.1178 - val_acc: 0.9554\n",
      "Epoch 29/100\n",
      "49813/49813 [==============================] - 5s 108us/sample - loss: 0.1356 - acc: 0.9511 - val_loss: 0.1124 - val_acc: 0.9565\n",
      "Epoch 30/100\n",
      "49813/49813 [==============================] - 4s 84us/sample - loss: 0.1340 - acc: 0.9524 - val_loss: 0.1116 - val_acc: 0.9578\n",
      "Epoch 31/100\n",
      "49813/49813 [==============================] - 4s 70us/sample - loss: 0.1351 - acc: 0.9518 - val_loss: 0.1107 - val_acc: 0.9573\n",
      "Epoch 32/100\n",
      "49813/49813 [==============================] - 6s 122us/sample - loss: 0.1336 - acc: 0.9523 - val_loss: 0.1125 - val_acc: 0.9567\n",
      "Epoch 33/100\n",
      "49813/49813 [==============================] - 5s 101us/sample - loss: 0.1304 - acc: 0.9527 - val_loss: 0.1104 - val_acc: 0.9574\n",
      "Epoch 34/100\n",
      "49813/49813 [==============================] - 5s 97us/sample - loss: 0.1277 - acc: 0.9548 - val_loss: 0.1155 - val_acc: 0.9554\n",
      "Epoch 35/100\n",
      "49813/49813 [==============================] - 7s 134us/sample - loss: 0.1310 - acc: 0.9523 - val_loss: 0.1077 - val_acc: 0.9585\n",
      "Epoch 36/100\n",
      "49813/49813 [==============================] - 5s 98us/sample - loss: 0.1299 - acc: 0.9540 - val_loss: 0.1164 - val_acc: 0.9586\n",
      "Epoch 37/100\n",
      "49813/49813 [==============================] - 4s 81us/sample - loss: 0.1331 - acc: 0.9523 - val_loss: 0.1097 - val_acc: 0.9575\n",
      "Epoch 38/100\n",
      "49813/49813 [==============================] - 7s 131us/sample - loss: 0.1296 - acc: 0.9537 - val_loss: 0.1127 - val_acc: 0.9563\n",
      "Epoch 39/100\n",
      "49813/49813 [==============================] - 5s 99us/sample - loss: 0.1268 - acc: 0.9552 - val_loss: 0.1096 - val_acc: 0.9590\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49813/49813 [==============================] - 5s 95us/sample - loss: 0.1255 - acc: 0.9546 - val_loss: 0.1117 - val_acc: 0.9571\n",
      "Epoch 41/100\n",
      "49813/49813 [==============================] - 6s 129us/sample - loss: 0.1276 - acc: 0.9547 - val_loss: 0.1115 - val_acc: 0.9570\n",
      "Epoch 42/100\n",
      "49813/49813 [==============================] - 5s 101us/sample - loss: 0.1203 - acc: 0.9574 - val_loss: 0.1153 - val_acc: 0.9558\n",
      "Epoch 43/100\n",
      "49813/49813 [==============================] - 4s 82us/sample - loss: 0.1235 - acc: 0.9566 - val_loss: 0.1153 - val_acc: 0.9582\n",
      "Epoch 44/100\n",
      "49813/49813 [==============================] - 4s 82us/sample - loss: 0.1264 - acc: 0.9557 - val_loss: 0.1078 - val_acc: 0.9585\n",
      "Epoch 45/100\n",
      "49813/49813 [==============================] - 4s 83us/sample - loss: 0.1265 - acc: 0.9557 - val_loss: 0.1119 - val_acc: 0.9567\n",
      "Epoch 46/100\n",
      "49813/49813 [==============================] - 3s 69us/sample - loss: 0.1225 - acc: 0.9563 - val_loss: 0.1119 - val_acc: 0.9572\n",
      "Epoch 47/100\n",
      "49813/49813 [==============================] - 3s 67us/sample - loss: 0.1230 - acc: 0.9575 - val_loss: 0.1102 - val_acc: 0.9586\n",
      "Epoch 48/100\n",
      "49813/49813 [==============================] - 3s 67us/sample - loss: 0.1241 - acc: 0.9576 - val_loss: 0.1087 - val_acc: 0.9581\n",
      "Epoch 49/100\n",
      "49813/49813 [==============================] - 3s 62us/sample - loss: 0.1221 - acc: 0.9573 - val_loss: 0.1103 - val_acc: 0.9586\n",
      "Epoch 50/100\n",
      "49813/49813 [==============================] - 3s 61us/sample - loss: 0.1207 - acc: 0.9581 - val_loss: 0.1090 - val_acc: 0.9578\n",
      "Epoch 51/100\n",
      "49813/49813 [==============================] - 3s 61us/sample - loss: 0.1210 - acc: 0.9570 - val_loss: 0.1155 - val_acc: 0.9546\n",
      "Epoch 52/100\n",
      "49813/49813 [==============================] - 3s 60us/sample - loss: 0.1184 - acc: 0.9571 - val_loss: 0.1075 - val_acc: 0.9590\n",
      "Epoch 53/100\n",
      "49813/49813 [==============================] - 3s 61us/sample - loss: 0.1180 - acc: 0.9570 - val_loss: 0.1101 - val_acc: 0.9575\n",
      "Epoch 54/100\n",
      "49813/49813 [==============================] - 3s 68us/sample - loss: 0.1171 - acc: 0.9578 - val_loss: 0.1073 - val_acc: 0.9597\n",
      "Epoch 55/100\n",
      "49813/49813 [==============================] - 3s 67us/sample - loss: 0.1195 - acc: 0.9575 - val_loss: 0.1086 - val_acc: 0.9592\n",
      "Epoch 56/100\n",
      "49813/49813 [==============================] - 3s 62us/sample - loss: 0.1183 - acc: 0.9587 - val_loss: 0.1102 - val_acc: 0.9590\n",
      "Epoch 57/100\n",
      "49813/49813 [==============================] - 3s 62us/sample - loss: 0.1197 - acc: 0.9578 - val_loss: 0.1084 - val_acc: 0.9589\n",
      "Epoch 58/100\n",
      "49813/49813 [==============================] - 3s 62us/sample - loss: 0.1161 - acc: 0.9589 - val_loss: 0.1098 - val_acc: 0.9588\n",
      "Epoch 59/100\n",
      "49813/49813 [==============================] - 7s 132us/sample - loss: 0.1147 - acc: 0.9580 - val_loss: 0.1126 - val_acc: 0.9581\n",
      "Epoch 60/100\n",
      "49813/49813 [==============================] - 5s 94us/sample - loss: 0.1137 - acc: 0.9602 - val_loss: 0.1079 - val_acc: 0.9603\n",
      "Epoch 61/100\n",
      "49813/49813 [==============================] - 4s 80us/sample - loss: 0.1148 - acc: 0.9589 - val_loss: 0.1063 - val_acc: 0.9610\n",
      "Epoch 62/100\n",
      "49813/49813 [==============================] - 4s 80us/sample - loss: 0.1148 - acc: 0.9596 - val_loss: 0.1086 - val_acc: 0.9602\n",
      "Epoch 63/100\n",
      "49813/49813 [==============================] - 4s 81us/sample - loss: 0.1122 - acc: 0.9600 - val_loss: 0.1088 - val_acc: 0.9602\n",
      "Epoch 64/100\n",
      "49813/49813 [==============================] - 4s 80us/sample - loss: 0.1092 - acc: 0.9618 - val_loss: 0.1075 - val_acc: 0.9597\n",
      "Epoch 65/100\n",
      "49813/49813 [==============================] - 7s 133us/sample - loss: 0.1136 - acc: 0.9601 - val_loss: 0.1095 - val_acc: 0.9594\n",
      "Epoch 66/100\n",
      "49813/49813 [==============================] - 5s 97us/sample - loss: 0.1149 - acc: 0.9593 - val_loss: 0.1148 - val_acc: 0.9596\n",
      "Epoch 67/100\n",
      "49813/49813 [==============================] - 4s 83us/sample - loss: 0.1149 - acc: 0.9588 - val_loss: 0.1071 - val_acc: 0.9607\n",
      "Epoch 68/100\n",
      "49813/49813 [==============================] - 4s 72us/sample - loss: 0.1112 - acc: 0.9606 - val_loss: 0.1102 - val_acc: 0.9593\n",
      "Epoch 69/100\n",
      "49813/49813 [==============================] - 4s 73us/sample - loss: 0.1114 - acc: 0.9608 - val_loss: 0.1063 - val_acc: 0.9612\n",
      "Epoch 70/100\n",
      "49813/49813 [==============================] - 4s 72us/sample - loss: 0.1132 - acc: 0.9604 - val_loss: 0.1094 - val_acc: 0.9594\n",
      "Epoch 71/100\n",
      "49813/49813 [==============================] - 4s 72us/sample - loss: 0.1093 - acc: 0.9606 - val_loss: 0.1101 - val_acc: 0.9596\n",
      "Epoch 72/100\n",
      "49813/49813 [==============================] - 4s 72us/sample - loss: 0.1120 - acc: 0.9601 - val_loss: 0.1089 - val_acc: 0.9608\n",
      "Epoch 73/100\n",
      "49813/49813 [==============================] - 4s 80us/sample - loss: 0.1086 - acc: 0.9615 - val_loss: 0.1095 - val_acc: 0.9588\n",
      "Epoch 74/100\n",
      "49813/49813 [==============================] - 4s 81us/sample - loss: 0.1061 - acc: 0.9620 - val_loss: 0.1137 - val_acc: 0.9589\n",
      "Epoch 75/100\n",
      "49813/49813 [==============================] - 7s 136us/sample - loss: 0.1102 - acc: 0.9605 - val_loss: 0.1086 - val_acc: 0.9606\n",
      "Epoch 76/100\n",
      "49813/49813 [==============================] - 4s 72us/sample - loss: 0.1095 - acc: 0.9611 - val_loss: 0.1090 - val_acc: 0.9586\n",
      "Epoch 77/100\n",
      "49813/49813 [==============================] - 3s 64us/sample - loss: 0.1069 - acc: 0.9616 - val_loss: 0.1095 - val_acc: 0.9580\n",
      "Epoch 78/100\n",
      "49813/49813 [==============================] - 3s 66us/sample - loss: 0.1113 - acc: 0.9604 - val_loss: 0.1070 - val_acc: 0.9601\n",
      "Epoch 79/100\n",
      "49813/49813 [==============================] - 3s 66us/sample - loss: 0.1088 - acc: 0.9625 - val_loss: 0.1080 - val_acc: 0.9599\n",
      "Epoch 80/100\n",
      "49813/49813 [==============================] - 3s 64us/sample - loss: 0.1061 - acc: 0.9634 - val_loss: 0.1097 - val_acc: 0.9596\n",
      "Epoch 81/100\n",
      "49813/49813 [==============================] - 3s 63us/sample - loss: 0.1089 - acc: 0.9619 - val_loss: 0.1087 - val_acc: 0.9599\n",
      "Epoch 82/100\n",
      "49813/49813 [==============================] - 3s 63us/sample - loss: 0.1076 - acc: 0.9628 - val_loss: 0.1097 - val_acc: 0.9594\n",
      "Epoch 83/100\n",
      "49813/49813 [==============================] - 3s 63us/sample - loss: 0.1094 - acc: 0.9614 - val_loss: 0.1110 - val_acc: 0.9582\n",
      "Epoch 84/100\n",
      "49813/49813 [==============================] - 3s 63us/sample - loss: 0.1047 - acc: 0.9632 - val_loss: 0.1123 - val_acc: 0.9600\n",
      "Epoch 85/100\n",
      "49813/49813 [==============================] - 3s 63us/sample - loss: 0.1048 - acc: 0.9627 - val_loss: 0.1074 - val_acc: 0.9607\n",
      "Epoch 86/100\n",
      "49813/49813 [==============================] - 3s 63us/sample - loss: 0.1099 - acc: 0.9623 - val_loss: 0.1141 - val_acc: 0.9584\n",
      "Epoch 87/100\n",
      "49813/49813 [==============================] - 3s 63us/sample - loss: 0.1049 - acc: 0.9620 - val_loss: 0.1153 - val_acc: 0.9591\n",
      "Epoch 88/100\n",
      "49813/49813 [==============================] - 3s 63us/sample - loss: 0.1069 - acc: 0.9616 - val_loss: 0.1107 - val_acc: 0.9605\n",
      "Epoch 89/100\n",
      "49813/49813 [==============================] - 3s 63us/sample - loss: 0.1073 - acc: 0.9612 - val_loss: 0.1099 - val_acc: 0.9589\n",
      "Epoch 90/100\n",
      "49813/49813 [==============================] - 3s 63us/sample - loss: 0.1031 - acc: 0.9625 - val_loss: 0.1097 - val_acc: 0.9588\n",
      "Epoch 91/100\n",
      "49813/49813 [==============================] - 3s 64us/sample - loss: 0.1094 - acc: 0.9618 - val_loss: 0.1090 - val_acc: 0.9599\n",
      "Epoch 92/100\n",
      "49813/49813 [==============================] - 7s 139us/sample - loss: 0.1033 - acc: 0.9625 - val_loss: 0.1105 - val_acc: 0.9598\n",
      "Epoch 93/100\n",
      "49813/49813 [==============================] - 5s 105us/sample - loss: 0.1019 - acc: 0.9632 - val_loss: 0.1083 - val_acc: 0.9600\n",
      "Epoch 94/100\n",
      "49813/49813 [==============================] - 4s 87us/sample - loss: 0.1047 - acc: 0.9635 - val_loss: 0.1087 - val_acc: 0.9613\n",
      "Epoch 95/100\n",
      "49813/49813 [==============================] - 3s 70us/sample - loss: 0.1019 - acc: 0.9635 - val_loss: 0.1119 - val_acc: 0.9603\n",
      "Epoch 96/100\n",
      "49813/49813 [==============================] - 3s 69us/sample - loss: 0.1007 - acc: 0.9635 - val_loss: 0.1102 - val_acc: 0.9598\n",
      "Epoch 97/100\n",
      "49813/49813 [==============================] - 3s 68us/sample - loss: 0.1010 - acc: 0.9644 - val_loss: 0.1099 - val_acc: 0.9607\n",
      "Epoch 98/100\n",
      "49813/49813 [==============================] - 3s 68us/sample - loss: 0.1019 - acc: 0.9639 - val_loss: 0.1110 - val_acc: 0.9595\n",
      "Epoch 99/100\n",
      "49813/49813 [==============================] - 7s 146us/sample - loss: 0.1035 - acc: 0.9643 - val_loss: 0.1125 - val_acc: 0.9602\n",
      "Epoch 100/100\n",
      "49813/49813 [==============================] - 6s 127us/sample - loss: 0.1020 - acc: 0.9644 - val_loss: 0.1104 - val_acc: 0.9599\n",
      "Score for fold 4: Accuracy of 96.376776680318%\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Accuracy: 95.92407014839083%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Accuracy: 96.39622277895549%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Accuracy: 96.17441580342087%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 4 - Accuracy: 96.376776680318%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 96.2178713527713 (+- 0.19056997849177634)\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "num_folds = 4\n",
    "batch_size = 128\n",
    "epochs = 100\n",
    "validation_split = 0.2\n",
    "verbose = 1\n",
    "\n",
    "best_acc = 0\n",
    "\n",
    "acc_per_fold = []\n",
    "\n",
    "kfold = KFold(n_splits=num_folds, shuffle=False)\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "for train, test in kfold.split(inputs, targets):\n",
    "\n",
    "    model = get_model(input_size, len(classes))\n",
    "    model.compile(optimizer=optimizer, loss=loss_function, metrics=['accuracy'])\n",
    "\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "    history = model.fit(inputs[train], targets[train], validation_split=validation_split, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "\n",
    "    metrics = evaluate(model, inputs[test], targets[test])\n",
    "    acc = metrics[0]\n",
    "    print(f'Score for fold {fold_no}: Accuracy of {acc*100}%')\n",
    "    acc_per_fold.append(acc * 100)\n",
    "\n",
    "    if(acc > best_acc):\n",
    "        best_acc = acc\n",
    "        best_metrics = metrics\n",
    "        best_model = model\n",
    "        best_model_history = history\n",
    "\n",
    "    fold_no = fold_no + 1\n",
    "\n",
    "    print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'> Fold {i+1} - Accuracy: {acc_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print('------------------------------------------------------------------------')\n",
    "\n",
    "history = best_model_history\n",
    "model = best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.963962\n",
      "------------------------------------------------------------------------\n",
      "Class: Mouse\n",
      "Precision: 0.960232\n",
      "Recall: 0.967328\n",
      "F1 score: 0.963767\n",
      "ROC AUC: 0.994224\n",
      "------------------------------------------------------------------------\n",
      "Class: Human\n",
      "Precision: 0.967680\n",
      "Recall: 0.960657\n",
      "F1 score: 0.964156\n",
      "ROC AUC: 0.994224\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('Best accuracy: %f' % best_acc)\n",
    "\n",
    "for i, class_name in enumerate(classes):\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print('Class: ' + class_name)\n",
    "    print('Precision: %f' % best_metrics[1][i])\n",
    "    print('Recall: %f' % best_metrics[2][i])\n",
    "    print('F1 score: %f' % best_metrics[3][i])\n",
    "    print('ROC AUC: %f' % best_metrics[4][i])\n",
    "print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10,10))\n",
    "sns.heatmap(best_metrics[5], ax=ax, vmin=0, vmax=1, center=0, square=True, cbar_kws={\"shrink\": 0.7}, xticklabels=classes, yticklabels=classes, annot=True, fmt=\"f\")\n",
    "ax.set_title(\"Confusion matrix\")\n",
    "ax.set_xlabel('Estimated classes')\n",
    "ax.set_ylabel('Real classes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model\n",
    "\n",
    "[TODO] write the path of the folder where you want your model to be saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\ProjetSemestre\\lib\\site-packages\\tensorflow\\python\\saved_model\\signature_def_utils_impl.py:205: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: models/classification\\saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "save_history(history, 'models/history.json')\n",
    "save_model(model, mean_values, std_values, 'models/classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
